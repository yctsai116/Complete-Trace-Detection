{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import math\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pm4py.objects.log.util import general as log_util\n",
    "from pm4py.objects.log.util import xes\n",
    "import tkinter\n",
    "import matplotlib \n",
    "matplotlib.use('TkAgg')\n",
    "import seaborn as sns\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inductive miner in this version has to adjust the noise threshold in pm4py.algo.discovery.inductive.util\n",
    "# We check the noise threshold here\n",
    "from pm4py.algo.discovery.inductive.util import shared_constants\n",
    "shared_constants.NOISE_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a XES event log\n",
    "from pm4py.objects.log.importer.xes import factory as xes_importer\n",
    "log = xes_importer.import_log('BPI_2017A.xes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.util import sorting\n",
    "from pm4py.objects.conversion.log.versions import to_event_stream\n",
    "from pm4py.objects.conversion.log.versions import to_event_log\n",
    "from pm4py.objects.log import log as log_instance\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "es1 = to_event_stream.transform_event_log_to_event_stream(log)\n",
    "es2 = sorting.sort_timestamp_stream(es1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "var=variants_filter.get_variants_sorted_by_count(variants_filter.get_variants(log))\n",
    "# print(es2.__len__())\n",
    "# print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  length of each trace (dict)\n",
    "tr_len = {}\n",
    "for case_index, case in enumerate(log):\n",
    "    tr_len[case.attributes[xes.DEFAULT_TRACEID_KEY]]=log[case_index].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mining for a Petri net\n",
    "from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "from pm4py.algo.discovery.inductive.versions.log import basic\n",
    "from pm4py.algo.discovery.inductive.versions.dfg import dfg_based\n",
    "net, initial_marking, final_marking = basic.apply(log)\n",
    "# net, initial_marking, final_marking = dfg_based.apply(log)\n",
    "# Petri net visualization\n",
    "from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "\n",
    "gviz_pn = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz_pn)\n",
    "# pn_vis_factory.save(gviz_pn,'/home/tsai/Dropbox/Process_Mining/OutputData/W18/Real_life/BPI_2017A.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.evaluation.replay_fitness.versions import alignment_based\n",
    "from pm4py.evaluation.replay_fitness.versions import token_replay\n",
    "from pm4py.evaluation.precision.versions import etconformance_token\n",
    "from pm4py.objects.petri.check_soundness import check_relaxed_soundness_net_in_fin_marking as soundness\n",
    "soundness(net, initial_marking, final_marking)\n",
    "fitness_wholeNet = alignment_based.apply(log, net, initial_marking, final_marking)\n",
    "precision_wholeNet = etconformance_token.apply(log, net, initial_marking, final_marking)\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of active trace on timestep\n",
    "\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "count_dic={}\n",
    "num_act_list=[]\n",
    "for event in es2:\n",
    "    if event[case_glue] in count_dic:\n",
    "        count_dic[event[case_glue]]=count_dic[event[case_glue]]-1\n",
    "    else:\n",
    "        count_dic[event[case_glue]]=tr_len[event[case_glue]]-1\n",
    "    num_act=0\n",
    "    for k,v in count_dic.items():\n",
    "        if v !=0:\n",
    "            num_act=num_act+1\n",
    "    num_act_list.append(num_act)\n",
    "plt.plot(num_act_list)\n",
    "plt.ylabel('# active')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability figure here (to choice the thresholds)\n",
    "es2 = sorting.sort_timestamp_stream(es1)\n",
    "\n",
    "# end event number\n",
    "num_events=es2.__len__()\n",
    "\n",
    "\n",
    "# start event number\n",
    "start_event=0\n",
    "# window size\n",
    "maxWinSize=5000\n",
    "\n",
    "# pick a time scale for the statistic unit\n",
    "# time_scale=60\n",
    "time_scale=3600        #hours\n",
    "# time_scale=3600*24     #days\n",
    "\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "CaseIndNT={}\n",
    "# \n",
    "# index and event :time list\n",
    "CaseIndTime={}\n",
    "CaseEvtTime={}\n",
    "\n",
    "\n",
    "# confusion matrix of predict complete and actual complete\n",
    "df_ConfM = pd.DataFrame()\n",
    "\n",
    "#  event stream SLinding window\n",
    "esSL=[]\n",
    "\n",
    "# for record the current index\n",
    "i=start_event\n",
    "\n",
    "# Statistic for first and last case-activity dict\n",
    "first_act={}\n",
    "\n",
    "# Drop Case List\n",
    "DCL={}\n",
    "\n",
    "# All activity counter\n",
    "AllactL={}\n",
    "AllactF={}\n",
    "Lastact={}\n",
    "Followact={}\n",
    "Firstact={}\n",
    "\n",
    "df_Last = pd.DataFrame()\n",
    "df_Follow = pd.DataFrame()\n",
    "df_First = pd.DataFrame()\n",
    "\n",
    "for event in itertools.islice(es2 , start_event, num_events):\n",
    "\n",
    "    glue = event[case_glue]\n",
    "    current_time=event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "    if event[xes.DEFAULT_NAME_KEY] not in AllactF:\n",
    "        AllactL['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        AllactF['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Lastact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Followact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Firstact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "    AllactF['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "# start statistic of distribution\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "# Dict:CaseIndTime record the {index activity:[after index activity time]}\n",
    "# Dict:CaseEvtTime record the {activity name:[after activity time]}\n",
    "    if glue in DCL:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            Lastact['%s'%(DCL[glue]['act'])]-=1\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex']=[DCL[glue]['index']+1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])]=event[xes.DEFAULT_NAME_KEY]\n",
    "            if (DCL[glue]['act']) not in CaseEvtTime:\n",
    "                CaseEvtTime[DCL[glue]['act']] = []\n",
    "            CaseEvtTime[DCL[glue]['act']].append((event[xes.DEFAULT_TIMESTAMP_KEY] - DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(DCL[glue]['index'])) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((DCL[glue]['index']))] = []\n",
    "            CaseIndTime['time_after_%d'%(DCL[glue]['index'])].append((event[xes.DEFAULT_TIMESTAMP_KEY] -DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "            Followact['%s'%(DCL[glue]['act'])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY] \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1  \n",
    "    else:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex'] = [1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['1_activity'] = event[xes.DEFAULT_NAME_KEY]\n",
    "            Firstact['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]  \n",
    "            # Count the follow activity \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1   \n",
    "\n",
    "# Do sliding window on list:esSL(event stream SLiding )\n",
    "# Dropping from the front of sliding window\n",
    "    if len(esSL) < maxWinSize:\n",
    "        esSL.append(event)\n",
    "    else:\n",
    "        if len(CaseIndNT[esSL[0][case_glue]]['EvtIndex'])==1:\n",
    "            # Count the last activity \n",
    "            Lastact['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1   \n",
    "            DCL[esSL[0][case_glue]]={}\n",
    "            DCL[esSL[0][case_glue]]['index']=CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1]\n",
    "            DCL[esSL[0][case_glue]]['act']=CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1])]\n",
    "            DCL[esSL[0][case_glue]]['time']=CaseIndNT[esSL[0][case_glue]]['event_time_newest']\n",
    "            del CaseIndNT[esSL[0][case_glue]]\n",
    "  \n",
    "        else:\n",
    "            del CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['time_after_%d'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0]\n",
    "# Count all the activity \n",
    "        AllactL['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1\n",
    "\n",
    "        del esSL[0]            \n",
    "        esSL.append(event)\n",
    "\n",
    "    Firstactdic={}\n",
    "    for k in Firstact:\n",
    "        if AllactF[k]>0:\n",
    "            Firstactdic[k]=Firstact[k]/AllactF[k]\n",
    "    df_First=df_First.append(Firstactdic , ignore_index=True)          \n",
    "\n",
    "    Lastactdic={}\n",
    "    for k in Lastact:\n",
    "        if AllactL[k]>0:\n",
    "            Lastactdic[k]=Lastact[k]/AllactL[k]\n",
    "    df_Last=df_Last.append(Lastactdic , ignore_index=True)    \n",
    "\n",
    "    Followactdic={}\n",
    "    for k in Followact:\n",
    "        if AllactF[k]>0:\n",
    "            Followactdic[k]=1-Followact[k]/AllactF[k]\n",
    "    df_Follow=df_Follow.append(Followactdic , ignore_index=True)   \n",
    "    \n",
    "    # for checking the code running state\n",
    "    if (i%500==0):\n",
    "        print(i,'/',(num_events))\n",
    "    i=i+1\n",
    "\n",
    "df_Last=df_Last.transpose()\n",
    "df_Follow=df_Follow.transpose()\n",
    "df_First=df_First.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot probability figure\n",
    "fig_row=2\n",
    "fig_col = math.ceil(len(Followactdic)/fig_row)\n",
    "\n",
    "f, axes = plt.subplots(fig_row,fig_col,figsize=(20,12))\n",
    "i=1\n",
    "for k in Followactdic:\n",
    "#     print(k)\n",
    "    plt.subplot(fig_row, fig_col, i)\n",
    "\n",
    "#     plt.plot(df_Last.loc[ '%s'%k , :],'C0',label=('Last'))\n",
    "#     plt.plot(df_Follow.loc[ '%s'%k , :],'C1',label=('Follow'))\n",
    "    plt.plot(df_First.loc[ '%s'%k , :],'C1',label=('First'))\n",
    "    plt.axhline(y=0.1, color='r',linestyle=':')\n",
    "#     plt.axhline(y=0.05, color='b',linestyle=':')\n",
    "#     plt.axhline(y=0.4, color='g',linestyle=':')\n",
    "#     plt.axhline(y=0.3, color='m',linestyle=':')\n",
    "    plt.axhline(y=0.9, color='r',linestyle=':')\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('%s'%k,fontsize=24)\n",
    "    plt.legend()\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_stream=es1\n",
    "WinSize=3000\n",
    "prob_th=0.1\n",
    "time_th=90\n",
    "Result='PM'\n",
    "\"\"\"\n",
    "    Apply probability estimation method on the input event stream\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    event_stream\n",
    "        Event Stream\n",
    "    WinSize\n",
    "        Size of sliding window\n",
    "    prob_th\n",
    "        Probability threshold\n",
    "    time_th\n",
    "        Time statistic threshold (percentile)\n",
    "    Result\n",
    "        'PM': only process mining result\n",
    "        'Cl': process mining result and classificatory result (very slow)\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    Data Frame\n",
    "\"\"\"\n",
    "    \n",
    "def threshold_cal(datacolumn,th=time_th, to_integer=False):\n",
    "    sorted(datacolumn)\n",
    "    Th = np.percentile(datacolumn , [th])\n",
    "    if to_integer==True:\n",
    "        Th=int(Th)\n",
    "    return Th\n",
    "\n",
    "es2 = sorting.sort_timestamp_stream(event_stream)\n",
    "\n",
    "# end event number\n",
    "num_events=es2.__len__()\n",
    "num_events=6000\n",
    "# start event number\n",
    "start_event=0\n",
    "\n",
    "# window size\n",
    "maxWinSize=WinSize\n",
    "\n",
    "\n",
    "# pick a time scale for the statistic unit\n",
    "# time_scale=60\n",
    "time_scale=3600        #hours\n",
    "# time_scale=3600*24     #days\n",
    "\n",
    "# probability threshold\n",
    "\n",
    "CaseIndNT={}\n",
    "EvtQ={}\n",
    "EvtQ_hist={}\n",
    "CaseEvtTime={}\n",
    "CaseIndTime={}\n",
    "\n",
    "# confusion matrix of predict complete and actual complete\n",
    "df_ConfM = pd.DataFrame()\n",
    "\n",
    "#  event stream SLinding window\n",
    "esSL=[]\n",
    "\n",
    "# for record the current index\n",
    "i=start_event\n",
    "\n",
    "# Statistic for first and last case-activity dict\n",
    "Firstact={}\n",
    "\n",
    "# Drop Case List\n",
    "DCL={}\n",
    "\n",
    "# All activity counter\n",
    "AllactL={}\n",
    "AllactF={}\n",
    "Lastact={}\n",
    "Followact={}\n",
    "\n",
    "df_Last = pd.DataFrame()\n",
    "df_Follow = pd.DataFrame()\n",
    "df_First = pd.DataFrame()\n",
    "\n",
    "for event in itertools.islice(es2 , start_event, num_events):\n",
    "\n",
    "    glue = event[case_glue]\n",
    "    current_time=event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "    if event[xes.DEFAULT_NAME_KEY] not in AllactF:\n",
    "        AllactL['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        AllactF['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Lastact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Firstact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Followact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "    AllactF['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "# start statistic of distribution\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "# Dict:CaseIndTime record the {index activity:[after index activity time]}\n",
    "# Dict:CaseEvtTime record the {activity name:[after activity time]}\n",
    "    if glue in DCL:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            Lastact['%s'%(DCL[glue]['act'])]-=1\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex']=[DCL[glue]['index']+1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])]=event[xes.DEFAULT_NAME_KEY]\n",
    "            if (DCL[glue]['act']) not in CaseEvtTime:\n",
    "                CaseEvtTime[DCL[glue]['act']] = []\n",
    "            CaseEvtTime[DCL[glue]['act']].append((event[xes.DEFAULT_TIMESTAMP_KEY] - DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(DCL[glue]['index'])) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((DCL[glue]['index']))] = []\n",
    "            CaseIndTime['time_after_%d'%(DCL[glue]['index'])].append((event[xes.DEFAULT_TIMESTAMP_KEY] -DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "            Followact['%s'%(DCL[glue]['act'])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY] \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1  \n",
    "    else:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex'] = [1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['1_activity'] = event[xes.DEFAULT_NAME_KEY]\n",
    "            Firstact['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]  \n",
    "            # Count the follow activity \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1   \n",
    "\n",
    "# Calculate the statistic value by func:threshold_cal    Calculate every certain step \n",
    "    if (i%200==0):\n",
    "# ============================event name threshold=========================================\n",
    "        for idx in CaseEvtTime:\n",
    "            EvtQ['%s'%idx]=threshold_cal(CaseEvtTime[idx],to_integer=True)\n",
    "        for idx in CaseEvtTime:\n",
    "            if idx not in EvtQ_hist:\n",
    "                EvtQ_hist['%s'%idx]=[]\n",
    "            EvtQ_hist['%s'%idx].append(threshold_cal(CaseEvtTime[idx],to_integer=True))\n",
    "#     # ====================================================================================        \n",
    "\n",
    "# Do sliding window on list:esSL(event stream SLiding )\n",
    "# Dropping from the front of sliding window\n",
    "    if len(esSL) < maxWinSize:\n",
    "        esSL.append(event)\n",
    "    else:\n",
    "        if len(CaseIndNT[esSL[0][case_glue]]['EvtIndex'])==1:\n",
    "            # Count the last activity \n",
    "            Lastact['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1   \n",
    "            DCL[esSL[0][case_glue]]={}\n",
    "            DCL[esSL[0][case_glue]]['index']=CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1]\n",
    "            DCL[esSL[0][case_glue]]['act']=CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1])]\n",
    "            DCL[esSL[0][case_glue]]['time']=CaseIndNT[esSL[0][case_glue]]['event_time_newest']\n",
    "            del CaseIndNT[esSL[0][case_glue]]\n",
    "\n",
    "        else:\n",
    "            del CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['time_after_%d'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0]\n",
    "# Count all the activity \n",
    "        AllactL['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1\n",
    "\n",
    "        del esSL[0]            \n",
    "        esSL.append(event)\n",
    "\n",
    "    Firstactdic={}\n",
    "    for k in Firstact:\n",
    "        if AllactF[k]>0:\n",
    "            Firstactdic[k]=Firstact[k]/AllactF[k]\n",
    "    df_First=df_First.append(Firstactdic , ignore_index=True)  \n",
    "\n",
    "    Lastactdic={}\n",
    "    for k in Lastact:\n",
    "        if AllactL[k]>0:\n",
    "            Lastactdic[k]=Lastact[k]/AllactL[k]\n",
    "    df_Last=df_Last.append(Lastactdic , ignore_index=True)    \n",
    "\n",
    "    Followactdic={}\n",
    "    for k in Followact:\n",
    "        if AllactF[k]>0:\n",
    "            Followactdic[k]=1-Followact[k]/AllactF[k]\n",
    "    df_Follow=df_Follow.append(Followactdic , ignore_index=True)   \n",
    "\n",
    "\n",
    "# Predict complete log by our method\n",
    "    StaResult={}\n",
    "    pred_cpt_list=[]\n",
    "\n",
    "# Record the result\n",
    "    if (i >= WinSize) and (i % 20 == 0):\n",
    "# Check the result of specific timestep\n",
    "#     if ((i==2080)):\n",
    "\n",
    "# Turn the list esSL to event stream and then event log    \n",
    "        ESSL=deepcopy(esSL)\n",
    "        es3=log_instance.EventStream(ESSL, attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                        omni_present=log.omni_present, extensions=log.extensions)\n",
    "        elog3 = to_event_log.transform_event_stream_to_event_log(es3)\n",
    "        SLRf_net, SLRf_initial_marking, SLRf_final_marking=basic.apply(elog3)\n",
    "\n",
    "        if soundness(SLRf_net, SLRf_initial_marking, SLRf_final_marking):\n",
    "            fitness_RawSWf = alignment_based.apply(log,SLRf_net, SLRf_initial_marking, SLRf_final_marking)['averageFitness']\n",
    "            precision_RawSWf = etconformance_token.apply(log, SLRf_net, SLRf_initial_marking, SLRf_final_marking)\n",
    "            F1_RawSWf = 2*(fitness_RawSWf*precision_RawSWf)/(fitness_RawSWf+precision_RawSWf)     \n",
    "        else:\n",
    "            fitness_RawSW = 0\n",
    "            precision_RawSW = 0   \n",
    "\n",
    "# Find the complete trace in the SLiding window event log \n",
    "        if Result=='Cl':\n",
    "            WinTrlen = {}\n",
    "            for case_index, case in enumerate(elog3):\n",
    "                WinTrlen[case.attributes[xes.DEFAULT_TRACEID_KEY]]=elog3[case_index].__len__()\n",
    "            complete_list=[]\n",
    "            for k,v in WinTrlen.items():\n",
    "                if v == tr_len[k]:\n",
    "                    complete_list.append(k)\n",
    "\n",
    "        for k in CaseIndNT:\n",
    "            StaResult[k]={}\n",
    "            StaResult[k]['Predict']=False\n",
    "            time_diff=(current_time - CaseIndNT[k]['event_time_newest']).total_seconds()/ time_scale  \n",
    "            klast_act=CaseIndNT[k]['%d_activity'%(CaseIndNT[k]['EvtIndex'][-1])]\n",
    "\n",
    "    #================================Condition of predicting true===========================================\n",
    "            if CaseIndNT[k]['EvtIndex'][0]==1:\n",
    "                if (Firstactdic['%s'%CaseIndNT[k]['1_activity']] > prob_th):\n",
    "                    if AllactF['%s'%klast_act] != 0:\n",
    "                        if (Followactdic['%s'%CaseIndNT[k]['%d_activity'%CaseIndNT[k]['EvtIndex'][-1]]] > (1-prob_th)):\n",
    "                            pred_cpt_list.append(k)\n",
    "                        elif(Followactdic['%s'%CaseIndNT[k]['%d_activity'%CaseIndNT[k]['EvtIndex'][-1]]] > prob_th):\n",
    "                            if (time_diff>=EvtQ['%s'%(CaseIndNT[k]['%d_activity'%(CaseIndNT[k]['EvtIndex'][-1])])]):\n",
    "                                pred_cpt_list.append(k)\n",
    "                                if Result=='Cl':\n",
    "                                    StaResult[k]['Predict']=True\n",
    "#     #====================================================================================================            \n",
    "#             Actual complete\n",
    "            if Result=='Cl':\n",
    "                if k in complete_list:\n",
    "                    StaResult[k]['Actual']=True\n",
    "                else:\n",
    "                    StaResult[k]['Actual']=False\n",
    "\n",
    "        esSLPredCpt=[]\n",
    "        for itessl in esSL:\n",
    "            if itessl[case_glue] in pred_cpt_list:\n",
    "                esSLPredCpt.append(itessl) \n",
    "\n",
    "        ESSL_PredCpt=deepcopy(esSLPredCpt)\n",
    "        es3_PredCpt=log_instance.EventStream(ESSL_PredCpt, attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                        omni_present=log.omni_present, extensions=log.extensions)\n",
    "        elog3_PredCpt = to_event_log.transform_event_stream_to_event_log(es3_PredCpt)\n",
    "        SLF_net, SLF_initial_marking, SLF_final_marking = inductive_miner.apply(elog3_PredCpt) \n",
    "\n",
    "        fitness_FilSW = alignment_based.apply(log,SLF_net, SLF_initial_marking, SLF_final_marking)['averageFitness']\n",
    "        precision_FilSW = etconformance_token.apply(log, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "        F1_FilSW = 2*(fitness_FilSW*precision_FilSW)/(fitness_FilSW+precision_FilSW)\n",
    "\n",
    "        if Result=='Cl':\n",
    "            df_StaResult=pd.DataFrame.from_dict(StaResult).transpose()\n",
    "            TP=len(df_StaResult[(df_StaResult['Predict']==True) & (df_StaResult['Actual']==True) ])\n",
    "            FP=len(df_StaResult[(df_StaResult['Predict']==True) & (df_StaResult['Actual']==False) ])\n",
    "            FN=len(df_StaResult[(df_StaResult['Predict']==False) & (df_StaResult['Actual']==True) ])\n",
    "            TN=len(df_StaResult[(df_StaResult['Predict']==False) & (df_StaResult['Actual']==False) ])\n",
    "            if ((TP+FP)==0):\n",
    "                Precision=0\n",
    "            else:\n",
    "                Precision=TP/(TP+FP)\n",
    "            if ((TP+FN)==0):\n",
    "                Recall=0\n",
    "            else:\n",
    "                Recall=TP/(TP+FN)\n",
    "            if ((Precision+Recall)==0):\n",
    "                F1=0\n",
    "            else:\n",
    "                F1=2*(Precision*Recall)/(Precision+Recall)\n",
    "            df_ConfM = df_ConfM.append({'index':i,'TP': TP,'FP':FP,'FN':FN,'TN':TN,'Precision':Precision,\n",
    "                                        'PM_fitness_Rawf':fitness_RawSWf,'PM_precision_Rawf':precision_RawSWf,'PM_F1_Rawf':F1_RawSWf,\n",
    "                                        'PM_fitness_Fil':fitness_FilSW,'PM_precision_Fil':precision_FilSW,'PM_F1_Fil':F1_FilSW,\n",
    "                                        'Recall':Recall,'F1':F1},ignore_index=True)\n",
    "        if Result=='PM':\n",
    "            df_ConfM = df_ConfM.append({'index':i,'PM_fitness_Fil':fitness_FilSW,'PM_precision_Fil':precision_FilSW,'PM_F1_Fil':F1_FilSW,\n",
    "                                        'PM_fitness_Rawf':fitness_RawSWf,'PM_precision_Rawf':precision_RawSWf,'PM_F1_Rawf':F1_RawSWf,\n",
    "                                        },ignore_index=True)                      \n",
    "\n",
    "    # for checking the code running state\n",
    "    if (i%500==0):\n",
    "        print(i,'/',(num_events))\n",
    "    i=i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax2 = plt.subplot(111)\n",
    "\n",
    "# ax2.plot(df_ConfM['index'],F,'k',label='All Predict True')\n",
    "ax2.plot(df_ConfM['index'],(df_ConfM['PM_F1_Fil']),'-C0',label='Filtered ')\n",
    "ax2.plot(df_ConfM['index'],(df_ConfM['PM_F1_Rawf']),'-C1',label='Raw ')\n",
    "\n",
    "ax2.legend()\n",
    "plt.title('F1 ( fitness & precision )',fontsize=25)\n",
    "# # plt.xlabel('test case')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.grid(True)\n",
    "# ax2.set_xlim([2000,12000])\n",
    "ax2.set_ylim([0,1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P=(df_ConfM['TP']+df_ConfM['FN'])/(df_ConfM['TP']+df_ConfM['FN']+df_ConfM['FP']+df_ConfM['TN'])\n",
    "F=2*P/(P+1)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax2 = plt.subplot(111)\n",
    "\n",
    "ax2.plot(df_ConfM['index'],F,'k',label='All Predict True')\n",
    "ax2.plot(df_ConfM['index'],(df_ConfM['F1']),'C1',label='Filtered w/ DCL')\n",
    "ax2.legend()\n",
    "# plt.title('F1 ( Precision & Recall )',fontsize=25)\n",
    "plt.xlabel('time step',fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.grid(True)\n",
    "# ax2.set_xlim([2000,12000])\n",
    "ax2.set_ylim([0,1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfiltered log\n",
    "for case_index, case in enumerate(elog3_PredCpt):\n",
    "    print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "    for event_index, event in enumerate(case):\n",
    "        print(\"event index: %d  event activity: %s  timestamp: %s\" % (event_index, event[\"concept:name\"],event[\"time:timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtered Petri net\n",
    "SLF_gviz_pn = pn_vis_factory.apply(SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "pn_vis_factory.view(SLF_gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_wholeNet = alignment_based.apply(log, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "precision_wholeNet = etconformance_token.apply(log, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pn_vis_factory.save(SL_gviz_pn,'/home/tsai/Dropbox/Process_Mining/OutputData/SW_F1_lowpoint1_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfiltered log\n",
    "for case_index, case in enumerate(elog3):\n",
    "    print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "    for event_index, event in enumerate(case):\n",
    "        print(\"event index: %d  event activity: %s  timestamp: %s\" % (event_index, event[\"concept:name\"],event[\"time:timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unfiltered Petri net\n",
    "SLR_gviz_pn = pn_vis_factory.apply(SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "pn_vis_factory.view(SLR_gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_wholeNet = alignment_based.apply(elog3, SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "precision_wholeNet = etconformance_token.apply(log, SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
