{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import math\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pm4py.objects.log.util import general as log_util\n",
    "from pm4py.objects.log.util import xes\n",
    "import tkinter\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import seaborn as sns\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a XES event log\n",
    "from pm4py.objects.log.importer.xes import factory as xes_importer\n",
    "# \n",
    "# log = xes_importer.import_log('/home/tsai/Dropbox/Process_Mining/ImputData/BPI_2012A_year.xes')\n",
    "# log = xes_importer.import_log('/home/tsai/Dropbox/Process_Mining/OutputData/W17/MySyn3/MySyn3.xes')\n",
    "# log = xes_importer.import_log('/home/tsai/Dropbox/Process_Mining/ImputData/Syn6.xes')\n",
    "# log = xes_importer.import_log('/home/tsai/Dropbox/Process_Mining/OutputData/W16/test21.xes')\n",
    "# log = xes_importer.import_log('/home/tsai/Dropbox/Process_Mining/OutputData/W17/test20.xes')\n",
    "log = xes_importer.import_log('/home/tsai/Dropbox/Process_Mining/OutputData/W17/MySyn3/MySyn3.xes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.util import sorting\n",
    "from pm4py.objects.conversion.log.versions import to_event_stream\n",
    "from pm4py.objects.conversion.log.versions import to_event_log\n",
    "from pm4py.objects.log import log as log_instance\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "es1 = to_event_stream.transform_event_log_to_event_stream(log)\n",
    "es2 = sorting.sort_timestamp_stream(es1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "# var=variants_filter.get_variants(gen_log)\n",
    "var=variants_filter.get_variants_sorted_by_count(variants_filter.get_variants(log))\n",
    "var[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for event_index,event in enumerate(sorting.sort_timestamp_stream(es2)):\n",
    "#     print(\"case:concept:name: %s  event activity: %s  timestamp: %s\" % (event['case:concept:name'], event[\"concept:name\"],event[\"time:timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es2.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  length of each trace (dict)\n",
    "tr_len = {}\n",
    "for case_index, case in enumerate(log):\n",
    "    tr_len[case.attributes[xes.DEFAULT_TRACEID_KEY]]=log[case_index].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.conversion.process_tree import factory as tree_to_petri\n",
    "from pm4py.algo.discovery.inductive.versions.dfg import dfg_based\n",
    "# Mining for a Petri net\n",
    "from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "# net, initial_marking, final_marking = dfg_based.apply(log)\n",
    "\n",
    "from pm4py.algo.discovery.inductive.versions.log import basic\n",
    "net, initial_marking, final_marking=basic.apply(log)\n",
    "# Petri net visualization\n",
    "from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "\n",
    "gviz_pn = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz_pn)\n",
    "# pn_vis_factory.save(gviz_pn,'/home/tsai/Dropbox/Process_Mining/OutputData/W17/test20_org.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.evaluation.replay_fitness.versions import alignment_based\n",
    "from pm4py.evaluation.precision.versions import etconformance_token\n",
    "from pm4py.objects.petri.check_soundness import check_relaxed_soundness_net_in_fin_marking as soundness\n",
    "soundness(net, initial_marking, final_marking)\n",
    "fitness_wholeNet = alignment_based.apply(log, net, initial_marking, final_marking)\n",
    "precision_wholeNet = etconformance_token.apply(log, net, initial_marking, final_marking)\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of active trace on timestep\n",
    "\n",
    "# call (length of trace-1)=count when first time see the trace\n",
    "# (count-1) when see the trace each time\n",
    "# add up all trace that count >=0\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "count_dic={}\n",
    "num_act_list=[]\n",
    "for event in es2:\n",
    "    if event[case_glue] in count_dic:\n",
    "        count_dic[event[case_glue]]=count_dic[event[case_glue]]-1\n",
    "    else:\n",
    "        count_dic[event[case_glue]]=tr_len[event[case_glue]]-1\n",
    "    num_act=0\n",
    "    for k,v in count_dic.items():\n",
    "        if v !=0:\n",
    "            num_act=num_act+1\n",
    "    num_act_list.append(num_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(num_act_list)\n",
    "plt.ylabel('# active')\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/OutputData/W16/test1_num_act_list.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##======================================Cal Prob================================================\n",
    "es2 = sorting.sort_timestamp_stream(es1)\n",
    "\n",
    "# end event number\n",
    "num_events=es2.__len__()\n",
    "num_events=12000\n",
    "\n",
    "# start event number\n",
    "start_event=1000\n",
    "# window size\n",
    "maxWinSize=3000\n",
    "\n",
    "# pick a time scale for the statistic unit\n",
    "time_scale=60\n",
    "# time_scale=3600        #hours\n",
    "# time_scale=3600*24     #days\n",
    "\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "CaseIndNT={}\n",
    "# \n",
    "# index and event :time list\n",
    "CaseIndTime={}\n",
    "CaseEvtTime={}\n",
    "\n",
    "\n",
    "# confusion matrix of predict complete and actual complete\n",
    "df_ConfM = pd.DataFrame()\n",
    "\n",
    "#  event stream SLinding window\n",
    "esSL=[]\n",
    "\n",
    "# for record the current index\n",
    "i=start_event\n",
    "\n",
    "# Statistic for first and last case-activity dict\n",
    "first_act={}\n",
    "\n",
    "# Drop Case List\n",
    "DCL={}\n",
    "\n",
    "# All activity counter\n",
    "AllactL={}\n",
    "AllactF={}\n",
    "Lastact={}\n",
    "Followact={}\n",
    "Firstact={}\n",
    "\n",
    "df_Last = pd.DataFrame()\n",
    "df_Follow = pd.DataFrame()\n",
    "df_First = pd.DataFrame()\n",
    "\n",
    "for event in itertools.islice(es2 , start_event, num_events):\n",
    "\n",
    "    glue = event[case_glue]\n",
    "    current_time=event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "    if event[xes.DEFAULT_NAME_KEY] not in AllactF:\n",
    "        AllactL['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        AllactF['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Lastact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Followact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Firstact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "    AllactF['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "# start statistic of distribution\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "# Dict:CaseIndTime record the {index activity:[after index activity time]}\n",
    "# Dict:CaseEvtTime record the {activity name:[after activity time]}\n",
    "    if glue in DCL:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            Lastact['%s'%(DCL[glue]['act'])]-=1\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex']=[DCL[glue]['index']+1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])]=event[xes.DEFAULT_NAME_KEY]\n",
    "            if (DCL[glue]['act']) not in CaseEvtTime:\n",
    "                CaseEvtTime[DCL[glue]['act']] = []\n",
    "            CaseEvtTime[DCL[glue]['act']].append((event[xes.DEFAULT_TIMESTAMP_KEY] - DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(DCL[glue]['index'])) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((DCL[glue]['index']))] = []\n",
    "            CaseIndTime['time_after_%d'%(DCL[glue]['index'])].append((event[xes.DEFAULT_TIMESTAMP_KEY] -DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "            Followact['%s'%(DCL[glue]['act'])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY] \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1  \n",
    "    else:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex'] = [1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['1_activity'] = event[xes.DEFAULT_NAME_KEY]\n",
    "            Firstact['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]  \n",
    "            # Count the follow activity \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1   \n",
    "\n",
    "# Do sliding window on list:esSL(event stream SLiding )\n",
    "# Dropping from the front of sliding window\n",
    "    if len(esSL) < maxWinSize:\n",
    "        esSL.append(event)\n",
    "    else:\n",
    "        if len(CaseIndNT[esSL[0][case_glue]]['EvtIndex'])==1:\n",
    "            # Count the last activity \n",
    "            Lastact['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1   \n",
    "            DCL[esSL[0][case_glue]]={}\n",
    "            DCL[esSL[0][case_glue]]['index']=CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1]\n",
    "            DCL[esSL[0][case_glue]]['act']=CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1])]\n",
    "            DCL[esSL[0][case_glue]]['time']=CaseIndNT[esSL[0][case_glue]]['event_time_newest']\n",
    "            del CaseIndNT[esSL[0][case_glue]]\n",
    "  \n",
    "        else:\n",
    "            del CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['time_after_%d'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0]\n",
    "# Count all the activity \n",
    "        AllactL['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1\n",
    "\n",
    "        del esSL[0]            \n",
    "        esSL.append(event)\n",
    "\n",
    "    Firstactdic={}\n",
    "    for k in Firstact:\n",
    "        if AllactF[k]>0:\n",
    "            Firstactdic[k]=Firstact[k]/AllactF[k]\n",
    "    df_First=df_First.append(Firstactdic , ignore_index=True)          \n",
    "\n",
    "    Lastactdic={}\n",
    "    for k in Lastact:\n",
    "        if AllactL[k]>0:\n",
    "            Lastactdic[k]=Lastact[k]/AllactL[k]\n",
    "    df_Last=df_Last.append(Lastactdic , ignore_index=True)    \n",
    "\n",
    "    Followactdic={}\n",
    "    for k in Followact:\n",
    "        if AllactF[k]>0:\n",
    "            Followactdic[k]=1-Followact[k]/AllactF[k]\n",
    "    df_Follow=df_Follow.append(Followactdic , ignore_index=True)   \n",
    "    \n",
    "    # for checking the code running state\n",
    "    if (i%500==0):\n",
    "        print(i,'/',(num_events))\n",
    "    i=i+1\n",
    "\n",
    "df_Last=df_Last.transpose()\n",
    "df_Follow=df_Follow.transpose()\n",
    "df_First=df_First.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_row=2\n",
    "fig_col = math.ceil(len(Followactdic)/fig_row)\n",
    "\n",
    "f, axes = plt.subplots(fig_row,fig_col,figsize=(20,12))\n",
    "i=1\n",
    "for k in Followactdic:\n",
    "#     print(k)\n",
    "    plt.subplot(fig_row, fig_col, i)\n",
    "\n",
    "#     plt.plot(df_Last.loc[ '%s'%k , :],'C0',label=('Last'))\n",
    "    plt.plot(df_Follow.loc[ '%s'%k , :],'C1',label=('Follow'))\n",
    "#     plt.plot(df_First.loc[ '%s'%k , :],'C1',label=('First'))\n",
    "    plt.axhline(y=0.1, color='r',linestyle=':')\n",
    "#     plt.axhline(y=0.15, color='y',linestyle=':')\n",
    "#     plt.axhline(y=0.05, color='g',linestyle=':')\n",
    "#     plt.axhline(y=0.18, color='m',linestyle=':')\n",
    "#     plt.axhline(y=0.9, color='r',linestyle=':')\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.title('%s'%k,fontsize=24)\n",
    "    plt.legend()\n",
    "    i+=1\n",
    "# plt.show()\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/OutputData/W17/test20_prob_start.png')\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/OutputData/W17/test20_prob_end.png')\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/OutputData/W18/Syn1_end.png')\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/Thesis/Syn1_DCL_start.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Follow\n",
    "# df_First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "# var=variants_filter.get_variants(gen_log)\n",
    "var=variants_filter.get_variants_sorted_by_count(variants_filter.get_variants(log))\n",
    "# var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##======================================w/ DCL================================================\n",
    "es2 = sorting.sort_timestamp_stream(es1)\n",
    "\n",
    "# end event number\n",
    "# num_events=es2.__len__()\n",
    "# num_events=12000\n",
    "if (es2.__len__())>13000:\n",
    "    num_events = 12000\n",
    "else:\n",
    "    num_events=es2.__len__()-1000\n",
    "# start event number\n",
    "start_event=1000\n",
    "# window size\n",
    "maxWinSize=3000\n",
    "\n",
    "# pick a time scale for the statistic unit\n",
    "time_scale=60\n",
    "# time_scale=3600        #hours\n",
    "# time_scale=3600*24     #days\n",
    "\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "CaseIndNT={}\n",
    "# \n",
    "# index and event :time list\n",
    "CaseIndTime={}\n",
    "CaseEvtTime={}\n",
    "\n",
    "# probability threshold\n",
    "prob_th=0.1\n",
    "parameters={'noiseThreshold':0.2}\n",
    "# confusion matrix of predict complete and actual complete\n",
    "df_ConfM = pd.DataFrame()\n",
    "\n",
    "#  event stream SLinding window\n",
    "esSL=[]\n",
    "\n",
    "# for record the current index\n",
    "i=start_event\n",
    "\n",
    "# Statistic for first and last case-activity dict\n",
    "Firstact={}\n",
    "\n",
    "# Drop Case List\n",
    "DCL={}\n",
    "\n",
    "# All activity counter\n",
    "AllactL={}\n",
    "AllactF={}\n",
    "Lastact={}\n",
    "Followact={}\n",
    "\n",
    "df_Last = pd.DataFrame()\n",
    "df_Follow = pd.DataFrame()\n",
    "df_First = pd.DataFrame()\n",
    "\n",
    "for event in itertools.islice(es2 , start_event, num_events):\n",
    "\n",
    "    glue = event[case_glue]\n",
    "    current_time=event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "    if event[xes.DEFAULT_NAME_KEY] not in AllactF:\n",
    "        AllactL['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        AllactF['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Lastact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Firstact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Followact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "    AllactF['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "# start statistic of distribution\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "# Dict:CaseIndTime record the {index activity:[after index activity time]}\n",
    "# Dict:CaseEvtTime record the {activity name:[after activity time]}\n",
    "    if glue in DCL:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            Lastact['%s'%(DCL[glue]['act'])]-=1\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex']=[DCL[glue]['index']+1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])]=event[xes.DEFAULT_NAME_KEY]\n",
    "            if (DCL[glue]['act']) not in CaseEvtTime:\n",
    "                CaseEvtTime[DCL[glue]['act']] = []\n",
    "            CaseEvtTime[DCL[glue]['act']].append((event[xes.DEFAULT_TIMESTAMP_KEY] - DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(DCL[glue]['index'])) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((DCL[glue]['index']))] = []\n",
    "            CaseIndTime['time_after_%d'%(DCL[glue]['index'])].append((event[xes.DEFAULT_TIMESTAMP_KEY] -DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "            Followact['%s'%(DCL[glue]['act'])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY] \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1  \n",
    "    else:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex'] = [1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['1_activity'] = event[xes.DEFAULT_NAME_KEY]\n",
    "            Firstact['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]  \n",
    "            # Count the follow activity \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1   \n",
    "\n",
    "# Do sliding window on list:esSL(event stream SLiding )\n",
    "# Dropping from the front of sliding window\n",
    "    if len(esSL) < maxWinSize:\n",
    "        esSL.append(event)\n",
    "    else:\n",
    "        if len(CaseIndNT[esSL[0][case_glue]]['EvtIndex'])==1:\n",
    "            # Count the last activity \n",
    "            Lastact['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1   \n",
    "            DCL[esSL[0][case_glue]]={}\n",
    "            DCL[esSL[0][case_glue]]['index']=CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1]\n",
    "            DCL[esSL[0][case_glue]]['act']=CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1])]\n",
    "            DCL[esSL[0][case_glue]]['time']=CaseIndNT[esSL[0][case_glue]]['event_time_newest']\n",
    "            del CaseIndNT[esSL[0][case_glue]]\n",
    "  \n",
    "        else:\n",
    "            del CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['time_after_%d'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0]\n",
    "# Count all the activity \n",
    "        AllactL['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1\n",
    "\n",
    "        del esSL[0]            \n",
    "        esSL.append(event)\n",
    "        \n",
    "    Firstactdic={}\n",
    "    for k in Firstact:\n",
    "        if AllactF[k]>0:\n",
    "            Firstactdic[k]=Firstact[k]/AllactF[k]\n",
    "    df_First=df_First.append(Firstactdic , ignore_index=True)  \n",
    "    \n",
    "    Lastactdic={}\n",
    "    for k in Lastact:\n",
    "        if AllactL[k]>0:\n",
    "            Lastactdic[k]=Lastact[k]/AllactL[k]\n",
    "    df_Last=df_Last.append(Lastactdic , ignore_index=True)    \n",
    "\n",
    "    Followactdic={}\n",
    "    for k in Followact:\n",
    "        if AllactF[k]>0:\n",
    "            Followactdic[k]=1-Followact[k]/AllactF[k]\n",
    "    df_Follow=df_Follow.append(Followactdic , ignore_index=True)   \n",
    "    \n",
    "\n",
    "    \n",
    "    if (i > 2000) and (i%20==0):\n",
    "#     if ((i%20==0)):\n",
    "#     if ((i==7880)):\n",
    "    # Turn the list esSL to event stream and then event log    \n",
    "        ESSL=deepcopy(esSL)\n",
    "        es3=log_instance.EventStream(ESSL, attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                        omni_present=log.omni_present, extensions=log.extensions)\n",
    "        elog3 = to_event_log.transform_event_stream_to_event_log(es3)\n",
    "\n",
    "#         R_tree=im_infrequent.apply_im_infrequent(log=elog3,f=0,parameters=None)\n",
    "#         SLR_net, SLR_initial_marking, SLR_final_marking=im_infrequent.apply_infrequent_petrinet(R_tree)\n",
    "#         SLR_net, SLR_initial_marking, SLR_final_marking=inductive_miner.apply(elog3)\n",
    "        SLRf_net, SLRf_initial_marking, SLRf_final_marking=basic.apply(elog3)\n",
    "        \n",
    "#         fitness_RawSW = alignment_based.apply(log,SLR_net, SLR_initial_marking, SLR_final_marking)['averageFitness']\n",
    "#         precision_RawSW = etconformance_token.apply(log, SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "#         F1_RawSW = 2*(fitness_RawSW*precision_RawSW)/(fitness_RawSW+precision_RawSW)\n",
    "        \n",
    "        \n",
    "#         Tree_f=dfg_based.apply_tree(elog3,parameters=parameters)\n",
    "#         SLRf_net, SLRf_initial_marking, SLRf_final_marking = tree_to_petri.apply(Tree_f)\n",
    "            \n",
    "        fitness_RawSWf = alignment_based.apply(log,SLRf_net, SLRf_initial_marking, SLRf_final_marking)['averageFitness']\n",
    "        precision_RawSWf = etconformance_token.apply(log, SLRf_net, SLRf_initial_marking, SLRf_final_marking)\n",
    "        F1_RawSWf = 2*(fitness_RawSWf*precision_RawSWf)/(fitness_RawSWf+precision_RawSWf)\n",
    "\n",
    "    # Find the complete trace in the SLiding window event log \n",
    "        WinTrlen = {}\n",
    "        for case_index, case in enumerate(elog3):\n",
    "            WinTrlen[case.attributes[xes.DEFAULT_TRACEID_KEY]]=elog3[case_index].__len__()\n",
    "        complete_list=[]\n",
    "        for k,v in WinTrlen.items():\n",
    "            if v == tr_len[k]:\n",
    "                complete_list.append(k)\n",
    "\n",
    "    # Predict the complete log by our method\n",
    "        StaResult={}\n",
    "        pred_cpt_list=[]\n",
    "        for k in CaseIndNT:\n",
    "            StaResult[k]={}\n",
    "            StaResult[k]['Predict']=False\n",
    "            time_diff=(current_time - CaseIndNT[k]['event_time_newest']).total_seconds()/ time_scale  \n",
    "            klast_act=CaseIndNT[k]['%d_activity'%(CaseIndNT[k]['EvtIndex'][-1])]\n",
    "    #================================Condition of predict true===========================================\n",
    "            if CaseIndNT[k]['EvtIndex'][0]==1:\n",
    "                if (Firstactdic['%s'%CaseIndNT[k]['1_activity']] > prob_th):\n",
    "                    if AllactF['%s'%klast_act] != 0:\n",
    "                        if (Followactdic['%s'%CaseIndNT[k]['%d_activity'%CaseIndNT[k]['EvtIndex'][-1]]] > prob_th):\n",
    "                            StaResult[k]['Predict']=True\n",
    "                            pred_cpt_list.append(k)              \n",
    "#     #====================================================================================================        \n",
    "\n",
    "#             Actual complete \n",
    "            if k in complete_list:\n",
    "                StaResult[k]['Actual']=True\n",
    "            else:\n",
    "                StaResult[k]['Actual']=False\n",
    "        esSLPredCpt=[]\n",
    "        for itessl in esSL:\n",
    "            if itessl[case_glue] in pred_cpt_list:\n",
    "                esSLPredCpt.append(itessl) \n",
    "                \n",
    "        ESSL_PredCpt=deepcopy(esSLPredCpt)\n",
    "        es3_PredCpt=log_instance.EventStream(ESSL_PredCpt, attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                        omni_present=log.omni_present, extensions=log.extensions)\n",
    "        elog3_PredCpt = to_event_log.transform_event_stream_to_event_log(es3_PredCpt)\n",
    "        \n",
    "#         F_tree=im_infrequent.apply_im_infrequent(log=elog3_PredCpt,f=0,parameters=None)\n",
    "#         SLF_net, SLF_initial_marking, SLF_final_marking=im_infrequent.apply_infrequent_petrinet(F_tree)\n",
    "        SLF_net, SLF_initial_marking, SLF_final_marking=inductive_miner.apply(elog3_PredCpt)\n",
    "        \n",
    "        fitness_FilSW = alignment_based.apply(log,SLF_net, SLF_initial_marking, SLF_final_marking)['averageFitness']\n",
    "        precision_FilSW = etconformance_token.apply(log, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "        F1_FilSW = 2*(fitness_FilSW*precision_FilSW)/((fitness_FilSW+precision_FilSW))\n",
    "        \n",
    "\n",
    "        SLR_net, SLR_initial_marking, SLR_final_marking = inductive_miner.apply(elog3) \n",
    "    \n",
    "        if soundness(SLR_net, SLR_initial_marking, SLR_final_marking):\n",
    "            fitness_RawSW = alignment_based.apply(log,SLR_net, SLR_initial_marking, SLR_final_marking)['averageFitness']\n",
    "            precision_RawSW = etconformance_token.apply(log, SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "        else:\n",
    "            fitness_RawSW = 0\n",
    "            precision_RawSW = 0\n",
    "        \n",
    "        df_StaResult=pd.DataFrame.from_dict(StaResult).transpose()\n",
    "        TP=len(df_StaResult[(df_StaResult['Predict']==True) & (df_StaResult['Actual']==True) ])\n",
    "        FP=len(df_StaResult[(df_StaResult['Predict']==True) & (df_StaResult['Actual']==False) ])\n",
    "        FN=len(df_StaResult[(df_StaResult['Predict']==False) & (df_StaResult['Actual']==True) ])\n",
    "        TN=len(df_StaResult[(df_StaResult['Predict']==False) & (df_StaResult['Actual']==False) ])\n",
    "        if ((TP+FP)==0):\n",
    "            Precision=0\n",
    "        else:\n",
    "            Precision=TP/(TP+FP)\n",
    "        if ((TP+FN)==0):\n",
    "            Recall=0\n",
    "        else:\n",
    "            Recall=TP/(TP+FN)\n",
    "        if ((Precision+Recall)==0):\n",
    "            F1=0\n",
    "        else:\n",
    "            F1=2*(Precision*Recall)/(Precision+Recall)\n",
    "#         df_ConfM = df_ConfM.append({'index':i,'PM_fitness_Fil':fitness_FilSW,'PM_precision_Fil':precision_FilSW,'PM_F1_Fil':F1_FilSW,\n",
    "# #                                     'PM_fitness_Raw':fitness_RawSW,'PM_precision_Raw':precision_RawSW,'PM_F1_Raw':F1_RawSW,\n",
    "#                                     'PM_fitness_Rawf':fitness_RawSWf,'PM_precision_Rawf':precision_RawSWf,'PM_F1_Rawf':F1_RawSWf,\n",
    "#                                     },ignore_index=True)\n",
    "        df_ConfM = df_ConfM.append({'index':i,'TP': TP,'FP':FP,'FN':FN,'TN':TN,'Precision':Precision,\n",
    "                                    'PM_fitness_Rawf':fitness_RawSWf,'PM_precision_Rawf':precision_RawSWf,'PM_F1_Rawf':F1_RawSWf,\n",
    "                                    'PM_fitness_Fil':fitness_FilSW,'PM_precision_Fil':precision_FilSW,'PM_F1_Fil':F1_FilSW,\n",
    "                                    'Recall':Recall,'F1':F1},ignore_index=True)\n",
    "    \n",
    "    # for checking the code running state\n",
    "    if (i%500==0):\n",
    "        print(i,'/',(num_events))\n",
    "    i=i+1\n",
    "\n",
    "df_Last=df_Last.transpose()\n",
    "df_Follow=df_Follow.transpose()\n",
    "df_First=df_First.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ConfM.to_csv('/home/tsai/Dropbox/Process_Mining/OutputData/W17/MySyn3/new/MySyn3_notime.csv',index=False)\n",
    "# df_ConfM_noTime = pd.read_csv('/home/tsai/Dropbox/Process_Mining/OutputData/W17/MySyn3/new/MySyn3_notime.csv')\n",
    "# df_ConfM_onlyTime = pd.read_csv('/home/tsai/Dropbox/Process_Mining/OutputData/W17/MySyn3/new/MySyn3_onlytime.csv')\n",
    "# df_ConfM1=df_ConfM\n",
    "# df_ConfMt=df_ConfM1\n",
    "# df_ConfM\n",
    "# df_ConfM = pd.read_csv('/home/tsai/Dropbox/Process_Mining/OutputData/W17/MySyn3/new/MySyn3_time.csv')\n",
    "# df_ConfM.to_csv('/home/tsai/Dropbox/Process_Mining/OutputData/W17/test20_nResult.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ConfM\n",
    "P=(df_ConfM['TP']+df_ConfM['FN'])/(df_ConfM['TP']+df_ConfM['FN']+df_ConfM['FP']+df_ConfM['TN'])\n",
    "F=2*P/(P+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax2 = plt.subplot(111)\n",
    "\n",
    "ax2.plot(df_ConfM['index'],F,'k',label='All Predict True')\n",
    "ax2.plot(df_ConfM['index'],(df_ConfM['F1']),'-C0',label='Filtered w/ time')\n",
    "# ax2.plot(df_ConfM_noTime['index'],(df_ConfM_noTime['F1']),'-C2',label='Filtered w/o time')\n",
    "ax2.plot(df_ConfM_onlyTime['index'],(df_ConfM_onlyTime['F1']),'--C2',label='Filtered only time')\n",
    "# ax2.plot(df_ConfM_notime['index'],(df_ConfM_notime['PM_F1_Fil']),'--C2',label='Filtered w/o DCL')\n",
    "# ax2.plot(df_ConfM['index'],(df_ConfM['PM_F1_Rawf']),':C2',label='Raw - infrequent')\n",
    "# ax2.plot(time2['index'],(time2['F1']),'C3',label='only start')\n",
    "# ax2.title.set_text('F1 (Wsize=4k)')\n",
    "ax2.legend()\n",
    "plt.xlabel('time step',fontsize=15)\n",
    "plt.ylabel('F1 ( precision , recall )',fontsize=15)\n",
    "# # plt.xlabel('test case')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.grid(True)\n",
    "# ax2.set_xlim([2000,12000])\n",
    "ax2.set_ylim([0,1.05])\n",
    "ax2.set_ylim([0.85,0.95])\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/OutputData/W17/test20_nResult.png')\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/Thesis/Syn3_2.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ConfM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax2 = plt.subplot(111)\n",
    "\n",
    "# 'PM_fitness_Raw':fitness_RawSW,'PM_precision_Raw':precision_RawSW,\n",
    "# 'PM_fitness_Fil':fitness_FilSW,'PM_precision_Fil':precision_FilSW,\n",
    "\n",
    "ax2.plot(df_ConfM['index'],df_ConfM['PM_F1_Rawf'],'k',label='All Predict True')\n",
    "ax2.plot(df_ConfM['index'],(df_ConfM['PM_F1_Fil']),'-C0',label='Filtered w/ time')\n",
    "# ax2.plot(df_ConfM_noTime['index'],(df_ConfM_noTime['PM_F1_Fil']),'-C2',label='Filtered w/o time')\n",
    "ax2.plot(df_ConfM_onlyTime['index'],(df_ConfM_onlyTime['PM_F1_Fil']),'--C2',label='Filtered only time')\n",
    "# ax2.plot(df_ConfM['index'],(df_ConfM['PM_fitness_Fil']),'C3.-',label='PM_fitness_Fil')\n",
    "# ax2.plot(df_ConfM_noTime['index'],(df_ConfM_noTime['PM_F1_Fil']),'C1--',label='time')\n",
    "# ax2.plot(time2['index'],(time2['F1']),'C3',label='only start')\n",
    "# ax2.title.set_text('PM fitness (Wsize=4k)')\n",
    "plt.xlabel('time step',fontsize=15)\n",
    "plt.ylabel('F1 ( Replay-Fitness , Precision )',fontsize=15)\n",
    "ax2.legend()\n",
    "# ax2.set_xlim([2000,12000])\n",
    "ax2.set_ylim([0,1.05])\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/OutputData/W16/test4_6.png')\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/Thesis/Syn3_3.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax2 = plt.subplot(111)\n",
    "\n",
    "# 'PM_fitness_Raw':fitness_RawSW,'PM_precision_Raw':precision_RawSW,\n",
    "# 'PM_fitness_Fil':fitness_FilSW,'PM_precision_Fil':precision_FilSW,\n",
    "\n",
    "# ax2.plot(df_ConfM['index'],F,'k',label='All Predict True')\n",
    "ax2.plot(df_ConfM['index'],(df_ConfM['PM_precision_Raw']),'C2.-',label='PM_precision_Raw')\n",
    "ax2.plot(df_ConfM['index'],(df_ConfM['PM_precision_Fil']),'C3.-',label='PM_precision_Fil')\n",
    "# ax2.plot(df_ConfM1['index'],(df_ConfM1['F1']),'C1--',label='time')\n",
    "# ax2.plot(time2['index'],(time2['F1']),'C3',label='only start')\n",
    "ax2.title.set_text('PM precision (Wsize=4k)')\n",
    "ax2.legend()\n",
    "# ax2.set_xlim([2000,12000])\n",
    "ax2.set_ylim([0,1.05])\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/OutputData/W16/test4_7.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=(df_ConfM['TP']+df_ConfM['FN'])/(df_ConfM['TP']+df_ConfM['FN']+df_ConfM['FP']+df_ConfM['TN'])\n",
    "F=2*P/(P+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax2 = plt.subplot(111)\n",
    "\n",
    "ax2.plot(df_ConfM['index'],F,'k',label='All Predict True')\n",
    "ax2.plot(df_ConfM['index'],(df_ConfM['F1']),'-C0',label='Filtered w/ Time')\n",
    "# ax2.plot(df_ConfM_noTime['index'],(df_ConfM_noTime['F1']),'-C3',label='Filtered w/o time')\n",
    "# ax2.plot(df_ConfM_noTime['index'],(df_ConfM_noTime['F1']),'C2',label='Filtered w/o Time')\n",
    "# ax2.plot(time2['index'],(time2['F1']),'C3',label='only start')\n",
    "# ax2.title.set_text('F1 (Wsize=4k)')\n",
    "ax2.legend()\n",
    "plt.title('F1 ( Precision & Recall )',fontsize=25)\n",
    "# # plt.xlabel('test case')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.grid(True)\n",
    "# ax2.set_xlim([2000,12000])\n",
    "ax2.set_ylim([0,1.05])\n",
    "# plt.savefig('/home/tsai/Dropbox/Process_Mining/OutputData/W17/Real_life/BPI_2012A/BPI_2012A_Result2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case_index, case in enumerate(elog3_PredCpt):\n",
    "    print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "    for event_index, event in enumerate(case):\n",
    "        print(\"event index: %d  event activity: %s  timestamp: %s\" % (event_index, event[\"concept:name\"],event[\"time:timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pm4py.algo.discovery.inductive.versions.infrequent import im_infrequent\n",
    "# tree=im_infrequent.apply_im_infrequent(log=elog3_PredCpt,f=0,parameters=None)\n",
    "# SLF_net, SLF_initial_marking, SLF_final_marking=im_infrequent.apply_infrequent_petrinet(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SLF_gviz_pn = pn_vis_factory.apply(SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "pn_vis_factory.view(SLF_gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_wholeNet = alignment_based.apply(log, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "precision_wholeNet = etconformance_token.apply(log, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pn_vis_factory.save(SL_gviz_pn,'/home/tsai/Dropbox/Process_Mining/OutputData/SW_F1_lowpoint1_2.png')\n",
    "from pm4py.objects.log.exporter.xes import factory as exporter\n",
    "# exporter.apply(elog3_PredCpt,'/home/tsai/Dropbox/Process_Mining/OutputData/W17/MySyn2/MySyn2_Raw.xes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for case_index, case in enumerate(elog3):\n",
    "# for case_index, case in enumerate(elog3_allwindow):\n",
    "    print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "    for event_index, event in enumerate(case):\n",
    "        print(\"event index: %d  event activity: %s  timestamp: %s\" % (event_index, event[\"concept:name\"],event[\"time:timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.exporter.xes import factory as exporter\n",
    "# exporter.apply(elog3,'/home/tsai/Dropbox/Process_Mining/OutputData/W16/test_R.xes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pm4py.algo.discovery.inductive.versions.infrequent import im_infrequent\n",
    "# Rf_tree=im_infrequent.apply_im_infrequent(log=elog3,f=0.2,parameters=None)\n",
    "# SLRf_net, SLRf_initial_marking, SLRf_final_marking=im_infrequent.apply_infrequent_petrinet(Rf_tree)\n",
    "\n",
    "SLR_gviz_pn = pn_vis_factory.apply(SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "pn_vis_factory.view(SLR_gviz_pn)\n",
    "from pm4py.objects.petri.exporter.versions import pnml\n",
    "# pnml.export_net(SLR_net, SLR_initial_marking,'/home/tsai/Dropbox/Process_Mining/OutputData/W17/test1/Raw_1.pnml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_wholeNet = alignment_based.apply(log, SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "precision_wholeNet = etconformance_token.apply(log, SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "net, initial_marking, final_marking = inductive_miner.apply(log)\n",
    "# Petri net visualization\n",
    "from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "\n",
    "gviz_pn = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------only keep full trace inside window----------------\n",
    "es2 = sorting.sort_timestamp_stream(es1)\n",
    "\n",
    "# How many events for event stream\n",
    "# EventsNum = es2.__len__()\n",
    "EventsNum = 10000\n",
    "\n",
    "\n",
    "i=0\n",
    "# df_fitness_new = pd.DataFrame()\n",
    "# df_precision_new = pd.DataFrame()\n",
    "\n",
    "for maxWinSize in [4000]:\n",
    "    esSL=[]\n",
    "\n",
    "    i=0\n",
    "    df_result=[]\n",
    "    for event in itertools.islice(es2 , 1000, EventsNum):\n",
    "\n",
    "        if len(esSL) < maxWinSize:\n",
    "            esSL.append(event)\n",
    "        else:\n",
    "            del esSL[0]\n",
    "            esSL.append(event)\n",
    "        if i ==7880: \n",
    "            ESSL_allwindow=deepcopy(esSL)\n",
    "            es3_allwindow=log_instance.EventStream(ESSL_allwindow, attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                            omni_present=log.omni_present, extensions=log.extensions)\n",
    "            elog3_allwindow = to_event_log.transform_event_stream_to_event_log(es3_allwindow)\n",
    "            SLR_net, SLR_initial_marking, SLR_final_marking = inductive_miner.apply(elog3_allwindow)\n",
    "\n",
    "#             WinTrlen={}\n",
    "#             for itessl in esSL:\n",
    "#                 if itessl[case_glue] in WinTrlen:\n",
    "#                     WinTrlen[itessl[case_glue]]+=1\n",
    "#                 else:\n",
    "#                     WinTrlen[itessl[case_glue]]=1\n",
    "#             fullInWin=[]\n",
    "#             for k,v in WinTrlen.items():\n",
    "#                 if v == tr_len[k]:\n",
    "#                     fullInWin.append(k)\n",
    "#             esSLfull=[]\n",
    "#             for itessl in esSL:\n",
    "#                 if itessl[case_glue] in fullInWin:\n",
    "#                     esSLfull.append(itessl)   \n",
    "#             ESSL=deepcopy(esSLfull)\n",
    "#             es3=log_instance.EventStream(ESSL, attributes=log.attributes, classifiers=log.classifiers,\n",
    "#                                             omni_present=log.omni_present, extensions=log.extensions)\n",
    "#             elog3 = to_event_log.transform_event_stream_to_event_log(es3)\n",
    "#             SLF_net, SLF_initial_marking, SLF_final_marking = inductive_miner.apply(elog3)\n",
    "        if (i%1000==0):\n",
    "            print(i,'/',EventsNum)\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLR_net, SLR_initial_marking, SLR_final_marking=inductive_miner.apply(elog3_allwindow)\n",
    "\n",
    "SLR_gviz_pn = pn_vis_factory.apply(SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "pn_vis_factory.view(SLR_gviz_pn)\n",
    "#         Rf_tree=im_infrequent.apply_im_infrequent(log=elog3,f=0.2,parameters=None)\n",
    "#         SLRf_net, SLRf_initial_marking, SLRf_final_marking=im_infrequent.apply_infrequent_petrinet(Rf_tree)\n",
    "\n",
    "fitness_RawSW = alignment_based.apply(log,SLR_net, SLR_initial_marking, SLR_final_marking)['averageFitness']\n",
    "precision_RawSW = etconformance_token.apply(log, SLR_net, SLR_initial_marking, SLR_final_marking)\n",
    "print('fitness_RawSW',fitness_RawSW)\n",
    "print('precision_RawSW',precision_RawSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.petri.importer import factory as net_importer\n",
    "my_net=net_importer.apply('/home/tsai/Dropbox/Process_Mining/OutputData/W17/MySyn2/MySyn2_Raw.pnml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SLT_gviz_pn = pn_vis_factory.apply(my_net[0], my_net[1], my_net[2])\n",
    "pn_vis_factory.view(SLT_gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_wholeNet = alignment_based.apply(log, my_net[0], my_net[1], my_net[2])\n",
    "precision_wholeNet = etconformance_token.apply(log, my_net[0], my_net[1], my_net[2])\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
