{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pm4py.objects.log.util import general as log_util\n",
    "from pm4py.objects.log.util import xes\n",
    "import matplotlib\n",
    "import random\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Mining for a Petri net\n",
    "from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "# Petri net visualization\n",
    "from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "\n",
    "graph_pn = pn_vis_factory.apply(gen_net, gen_im, gen_fm)\n",
    "pn_vis_factory.view(graph_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pm4py.objects.petri.exporter import factory as net_exporter\n",
    "# net_exporter.apply(gen_net, gen_im, '/home/tsai/Dropbox/Process_Mining/OutputData/W16/Gen_1.pnml',final_marking=gen_fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pm4py.objects.petri.importer import factory as net_importer\n",
    "# my_net=net_importer.apply('/home/tsai/Dropbox/Process_Mining/OutputData/W16/Gen_1.pnml')\n",
    "# # Mining for a Petri net\n",
    "# from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "# # Petri net visualization\n",
    "# from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "# gviz_my_net = pn_vis_factory.apply(my_net[0], my_net[1], my_net[2])\n",
    "# pn_vis_factory.view(gviz_my_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a XES event log\n",
    "from pm4py.objects.log.importer.xes import factory as xes_importer\n",
    "\n",
    "# log = xes_importer.import_log('/home/tsai/Dropbox/Process_Mining/OutputData/W13/MySyn_W1k.xes')\n",
    "# log1 = xes_importer.import_log('/home/tsai/Dropbox/Process_Mining/ImputData/Syn6.xes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.util import sorting\n",
    "from pm4py.objects.conversion.log.versions import to_event_stream\n",
    "from pm4py.objects.conversion.log.versions import to_event_log\n",
    "from pm4py.objects.log import log as log_instance\n",
    "# stream = sorting.sort_timestamp_stream(to_event_stream.transform_event_log_to_event_stream(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mining for a Petri net\n",
    "from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "net, initial_marking, final_marking = inductive_miner.apply(log)\n",
    "# Petri net visualization\n",
    "from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "\n",
    "gviz_pn = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.evaluation.replay_fitness.versions import alignment_based\n",
    "from pm4py.evaluation.precision.versions import etconformance_token\n",
    "fitness_wholeNet = alignment_based.apply(log, net, initial_marking, final_marking)\n",
    "precision_wholeNet = etconformance_token.apply(log, net, initial_marking, final_marking)\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_time=log[-1][-1]['time:timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "Tt=[['1','a'],['2','b'],['3','c'],['4','d']]\n",
    "for i in range(4):\n",
    "    random.seed(i)\n",
    "    print(\"random.choice() to select random item from list - \", random.choice(Tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[['Act_A','Act_B','Act_E','Act_F','Act_G','Act_H'],\n",
    "   ['Act_A','Act_C','Act_E','Act_F','Act_G','Act_H'],\n",
    "   ['Act_A','Act_B','Act_E','Act_G','Act_F','Act_H'],\n",
    "   ['Act_A','Act_C','Act_E','Act_G','Act_F','Act_H']]\n",
    "# L=[['Act_A','Act_B','Act_C','Act_D'],['Act_A','Act_C','Act_B','Act_D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1=[['Act_A','Act_B','Act_D','Act_E','Act_F','Act_G','Act_H'],\n",
    "   ['Act_A','Act_C','Act_D','Act_E','Act_F','Act_G','Act_H'],\n",
    "   ['Act_A','Act_B','Act_D','Act_E','Act_G','Act_F','Act_H'],\n",
    "   ['Act_A','Act_C','Act_D','Act_E','Act_G','Act_F','Act_H'],\n",
    "   ['Act_A','Act_B','Act_D','Act_E'],['Act_A','Act_C','Act_D','Act_E']]\n",
    "# L2=[['Act_A','Act_B','Act_D','Act_E','Act_F','Act_G','Act_H','Act_I'],\n",
    "#    ['Act_A','Act_B','Act_D','Act_E','Act_F','Act_G','Act_H','Act_I'],\n",
    "#    ['Act_A','Act_C','Act_D','Act_E','Act_G','Act_F','Act_H','Act_I'],\n",
    "#    ['Act_A','Act_C','Act_D','Act_E','Act_G','Act_F','Act_H','Act_I']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2=[['Act_A','Act_B','Act_C','Act_D','Act_E'],\n",
    "   ['Act_A','Act_B','Act_C','Act_E','Act_D'],\n",
    "   ['Act_A','Act_B','Act_D','Act_C','Act_E'],\n",
    "   ['Act_A','Act_B','Act_D','Act_E','Act_C'],\n",
    "   ['Act_A','Act_B','Act_E','Act_C','Act_D'],\n",
    "   ['Act_A','Act_B','Act_E','Act_D','Act_C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L3=[['Act_A','Act_C','Act_D','Act_E'],\n",
    "   ['Act_A','Act_B','Act_C','Act_E'],\n",
    "   ['Act_A','Act_B','Act_D','Act_C'],\n",
    "   ['Act_A','Act_B','Act_D','Act_E'],\n",
    "   ['Act_A','Act_B','Act_E','Act_C','Act_D'],\n",
    "   ['Act_A','Act_B','Act_E','Act_D','Act_C'],\n",
    "   ['Act_A','Act_B','Act_C','Act_D','Act_E'],\n",
    "   ['Act_A','Act_B','Act_C','Act_E','Act_D'],\n",
    "   ['Act_A','Act_B','Act_D'],\n",
    "   ['Act_A','Act_B','Act_D','Act_E','Act_C'],\n",
    "   ['Act_A'],\n",
    "   ['Act_A','Act_B','Act_E','Act_D','Act_C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L4=[['a','b','c','d'],['a','c','b','d'],['a','b','c','e'],['a','c','b','e']]\n",
    "L4=[['a','c','d'],['b','c','d'],['a','d','c'],['b','d','c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L4=[['a','b','c','d'],['a','b','c','d']]\n",
    "# L5=[['a'],['b'],['c'],['d'],['a','c'],['b','c'],['c','d'],['b','d'],['a','d'],['a','c','d'],['b','c','d'],['a','d','c'],['b','d','c']]\n",
    "L5=[['Act_A','Act_B','Act_D','Act_E','Act_F','Act_F','Act_G'],\n",
    "   ['Act_A','Act_C','Act_D','Act_E','Act_F','Act_F','Act_G'],\n",
    "   ['Act_A','Act_B','Act_E','Act_D','Act_F','Act_F','Act_G'],\n",
    "   ['Act_A','Act_C','Act_E','Act_D','Act_F','Act_F','Act_F','Act_G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log generator timestamp interval = 1 sec\n",
    "import pm4py.objects.log.log as log_instance\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "from datetime import timedelta\n",
    "curr_timestamp=datetime.datetime(2010, 1, 1, 0, 0, 0, 0, pytz.UTC)\n",
    "log = log_instance.EventLog()\n",
    "# How many cases to generate\n",
    "no_traces=100\n",
    "for i in range(no_traces):\n",
    "#     random.seed(i)\n",
    "    trace = log_instance.Trace()\n",
    "    trace.attributes[\"concept:name\"] = str(i)\n",
    "    #choose a TargetLog(TL) from Log repository\n",
    "    SL=random.choice(L)\n",
    "    for k in SL:\n",
    "        event = log_instance.Event()\n",
    "        event[\"concept:name\"] = k\n",
    "        event[\"time:timestamp\"] = curr_timestamp\n",
    "        trace.append(event)\n",
    "    # increases by 1 second\n",
    "        curr_timestamp = curr_timestamp + timedelta(hours=1)\n",
    "    if len(trace) > 0:\n",
    "        log.append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "net, initial_marking, final_marking = inductive_miner.apply(log)\n",
    "# Petri net visualization\n",
    "from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "\n",
    "gviz_pn = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz_pn)\n",
    "# pn_vis_factory.save(gviz_pn,'/home/tsai/Dropbox/Process_Mining/OutputData/Thesis_data/demo2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.conversion.log.versions import to_event_log\n",
    "\n",
    "pm4py.objects.log.exporter.xes.factory.export_log(log,'/home/tsai/Dropbox/Process_Mining/OutputData/Thesis_data/demo2.xes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = log_instance.Trace()\n",
    "trace.attributes[\"concept:name\"] = str(i)\n",
    "SL=['Act_A','Act_B','Act_H','Act_D','Act_E','Act_F','Act_G']\n",
    "# SL=['Act_A','Act_A','Act_H','Act_D','Act_E','Act_F','Act_G']\n",
    "# SL=['Act_A','Act_B','Act_C','Act_D','Act_E','Act_F','Act_G']\n",
    "# SL=['Act_A','Act_B','Act_D','Act_C']\n",
    "for k in SL:\n",
    "    event = log_instance.Event()\n",
    "    event[\"concept:name\"] = k\n",
    "    event[\"time:timestamp\"] = curr_timestamp\n",
    "    trace.append(event)\n",
    "# increases by 1 second\n",
    "    curr_timestamp = curr_timestamp + timedelta(hours=1)\n",
    "if len(trace) > 0:\n",
    "    log.append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.exporter.xes import factory as exporter\n",
    "from pm4py.objects.log.importer.xes import factory as xes_importer\n",
    "# exporter.apply(log,'/home/tsai/pm4py_mod/test3.xes')\n",
    "from pm4py.algo.discovery.inductive.util import shared_constants\n",
    "# shared_constants.NOISE_THRESHOLD\n",
    "# log = xes_importer.import_log('/home/tsai/pm4py_mod/test2.xes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.conversion.process_tree import factory as tree_to_petri\n",
    "# Mining for a Petri net\n",
    "from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "from pm4py.algo.discovery.inductive.versions.dfg import data_structures,dfg_based\n",
    "net, initial_marking, final_marking=dfg_based.apply(log)\n",
    "# tree_dfg=dfg_based.apply_tree(log,parameters={'noiseThreshold':0.2})\n",
    "# print(tree_dfg)\n",
    "from pm4py.algo.discovery.inductive.versions.log import basic\n",
    "# net, initial_marking, final_marking=basic.apply(log)\n",
    "# tree_basic=basic.apply_tree(log,parameters={'noiseThreshold':0.2})\n",
    "# print(tree_basic)\n",
    "# net, initial_marking, final_marking = inductive_miner.apply(log,parameters={'noiseThreshold':0.2},variant=inductive_miner.DFG_BASED)\n",
    "# net, initial_marking, final_marking = inductive_miner.apply(log,variant=inductive_miner.LOG_BASIC)\n",
    "\n",
    "# Petri net visualization\n",
    "# from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "\n",
    "gviz_pn = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mining for a Petri net\n",
    "# from pm4py.algo.discovery.inductive import factory as inductive_miner\n",
    "\n",
    "from pm4py.algo.discovery.inductive.versions.dfg import dfg_based as inductive_miner\n",
    "# tree = inductive_miner.apply_tree(log)\n",
    "\n",
    "# activity_key = parameters[pmutil.constants.PARAMETER_CONSTANT_ACTIVITY_KEY]\n",
    "dfg = [(k, v) for k, v in dfg_inst.apply(log, parameters={\n",
    "    pmutil.constants.PARAMETER_CONSTANT_ACTIVITY_KEY: activity_key}).items() if v > 0]\n",
    "start_activities = log_start_act_stats.get_start_activities(log, parameters=parameters)\n",
    "# gets the end activities from the log\n",
    "end_activities = log_end_act_stats.get_end_activities(log, parameters=parameters)\n",
    "\n",
    "# get the activities in the log\n",
    "activities = log_attributes_stats.get_attribute_values(log, activity_key)\n",
    "# noise_threshold=0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg\n",
    "# activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'noiseThreshold':0.2}\n",
    "tree=inductive_miner.apply_tree_dfg(dfg, parameters=parameters, activities=activities, contains_empty_traces=False, \n",
    "                                    start_activities=start_activities,end_activities=end_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.dfg.filtering import dfg_filtering\n",
    "dfg_filtering.clean_dfg_based_on_noise_thresh(dfg, activities, noise_threshold, parameters=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree\n",
    "net, initial_marking, final_marking = tree_to_petri.apply(tree)\n",
    "gviz_pn = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time stamp interval = 1 sec\n",
    "import pm4py.objects.log.log as log_instance\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "from datetime import timedelta\n",
    "curr_timestamp=datetime.datetime(2010, 1, 1, 0, 0, 0, 0, pytz.UTC)\n",
    "stream = log_instance.EventStream()\n",
    "# How many cases to generate\n",
    "no_traces=2000\n",
    "for i in range(no_traces):\n",
    "#     random.seed(i)\n",
    "    #choose a TargetLog(TL) from Log repository\n",
    "    SL=random.choice(L)\n",
    "    for k in SL:\n",
    "        event = log_instance.Event()\n",
    "        event[\"case:concept:name\"] = 'case_'+str(i)\n",
    "        event[\"concept:name\"] = k\n",
    "        event[\"time:timestamp\"] = curr_timestamp\n",
    "        trace.append(event)\n",
    "        curr_timestamp = curr_timestamp + timedelta(hours=6)\n",
    "        stream.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time interval setting\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "# time type = 1 , typical \n",
    "# time type = 2 , weekday\n",
    "# time type = 3 , intensive\n",
    "def time_after(act , ev_time):\n",
    "    if act == 'Act_A':\n",
    "        mu, sigma = 4, 1\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_B':\n",
    "        mu, sigma = 4, 2\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_C':\n",
    "        h = randint(3,5)\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_D':\n",
    "        mu, sigma = 2, 0.1\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_E':\n",
    "#         h = randint(8,40)\n",
    "        mu, sigma = 24, 0.5\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_F':\n",
    "        mu, sigma = 3, 2\n",
    "#         mu, sigma = 12, 4\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_G':\n",
    "        mu, sigma = 2, 0.1\n",
    "#         mu, sigma = 15, 5\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "#     if act == 'Act_H':\n",
    "#         h = 2\n",
    "#         return ev_time + timedelta(hours=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time interval setting\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "# time type = 1 , typical \n",
    "# time type = 2 , weekday\n",
    "# time type = 3 , intensive\n",
    "def time_after(act , ev_time):\n",
    "    if act == 'Act_A':\n",
    "        mu, sigma = 6, 0.1\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_B':\n",
    "        mu, sigma =6, 0.1\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_C':\n",
    "        mu, sigma = 6, 0.1\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_D':\n",
    "        mu, sigma = 6, 0.1\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)\n",
    "    \n",
    "    if act == 'Act_E':\n",
    "#         h = randint(8,40)\n",
    "        mu, sigma = 6, 0.1\n",
    "        g=np.random.normal(mu, sigma)\n",
    "        h = g if g > 0 else mu\n",
    "        return ev_time + timedelta(hours=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py.objects.log.log as log_instance\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "from datetime import timedelta\n",
    "start_timestamp = datetime.datetime(2010, 1, 1, 0, 0, 0, 0, pytz.UTC)\n",
    "# start_timestamp = stream[-1]['time:timestamp']\n",
    "trace_time = start_timestamp\n",
    "stream = log_instance.EventStream()\n",
    "# How many cases to generate\n",
    "no_traces=2500\n",
    "for i in range(no_traces):\n",
    "#     random.seed(i)\n",
    "    #choose a TargetLog(TL) from Log repository\n",
    "    SL=random.choice(L2)\n",
    "    mu, sigma = 0.1, 0.02\n",
    "#     mu, sigma = 1, 0.4\n",
    "#     mu, sigma = 2, 1\n",
    "    g=np.random.normal(mu, sigma)\n",
    "    trace_h = g if g > 0 else mu\n",
    "    trace_time = trace_time + timedelta(hours=trace_h)\n",
    "    event_time = trace_time\n",
    "    for k in SL:\n",
    "        event = log_instance.Event()\n",
    "        event[\"case:concept:name\"] = 'case_'+str(i)\n",
    "        event[\"concept:name\"] = k\n",
    "        event[\"time:timestamp\"] = event_time\n",
    "        event_time = time_after(k , event_time)\n",
    "        stream.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamd=deepcopy(stream)\n",
    "# from pm4py.objects.conversion.log.versions import to_event_log\n",
    "# mylog=to_event_log.transform_event_stream_to_event_log(streamd)\n",
    "pm4py.objects.log.exporter.xes.factory.export_log(mylog,'/home/tsai/Dropbox/Process_Mining/OutputData/Thesis_data/demo.xes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_missing_head(log, percent):\n",
    "# random.choice(log)\n",
    "    noise_item=random.choices(population=log, k=int(len(log)*percent/100))\n",
    "    noise_case=[]\n",
    "    for k in noise_item:\n",
    "        noise_case.append(k.attributes['concept:name'])\n",
    "#     print(noise_case)\n",
    "    traces={}\n",
    "    for tr in log:\n",
    "        trace_attr={}\n",
    "        glue=tr.attributes['concept:name']\n",
    "        trace_attr[xes.DEFAULT_TRACEID_KEY] = glue\n",
    "        traces[glue] = log_instance.Trace(attributes=trace_attr)\n",
    "        if tr.attributes['concept:name'] in noise_case:\n",
    "            for nu,ev in enumerate(tr):\n",
    "                if nu > 0:\n",
    "                    traces[glue].append(ev)\n",
    "        else:\n",
    "            for ev in tr:\n",
    "                traces[glue].append(ev)\n",
    "    return log_instance.EventLog(traces.values(), attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                     omni_present=log.omni_present, extensions=log.extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_log=Noise_missing_head(log,10)\n",
    "noise_stream = sorting.sort_timestamp_stream(to_event_stream.transform_event_log_to_event_stream(noise_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_missing_tail(log, percent):\n",
    "# random.choice(log)\n",
    "    noise_item=random.choices(population=log, k=int(len(log)*percent/100))\n",
    "    noise_case=[]\n",
    "    for k in noise_item:\n",
    "        noise_case.append(k.attributes['concept:name'])\n",
    "#     print(noise_case)\n",
    "    traces={}\n",
    "    for tr in log:\n",
    "        trace_attr={}\n",
    "        glue=tr.attributes['concept:name']\n",
    "        trace_attr[xes.DEFAULT_TRACEID_KEY] = glue\n",
    "        traces[glue] = log_instance.Trace(attributes=trace_attr)        \n",
    "        if tr.attributes['concept:name'] in noise_case:\n",
    "            trl=len(tr)\n",
    "            for nu,ev in enumerate(tr):\n",
    "                if nu < (trl-1):\n",
    "                    traces[glue].append(ev)\n",
    "        else:\n",
    "            for ev in tr:\n",
    "                traces[glue].append(ev)\n",
    "    return log_instance.EventLog(traces.values(), attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                     omni_present=log.omni_present, extensions=log.extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_log=Noise_missing_tail(log,10)\n",
    "noise_stream = sorting.sort_timestamp_stream(to_event_stream.transform_event_log_to_event_stream(noise_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_double_head(log, percent):\n",
    "# random.choice(log)\n",
    "    noise_item=random.choices(population=log, k=int(len(log)*percent/100))\n",
    "    noise_case=[]\n",
    "    for k in noise_item:\n",
    "        noise_case.append(k.attributes['concept:name'])\n",
    "#     print(noise_case)\n",
    "    traces={}\n",
    "    for tr in log:\n",
    "        trace_attr={}\n",
    "        glue=tr.attributes['concept:name']\n",
    "        trace_attr[xes.DEFAULT_TRACEID_KEY] = glue\n",
    "        traces[glue] = log_instance.Trace(attributes=trace_attr)\n",
    "        if tr.attributes['concept:name'] in noise_case:\n",
    "            for nu,ev in enumerate(tr):\n",
    "                traces[glue].append(ev)\n",
    "                if nu == 0:\n",
    "                    traces[glue].append(ev)\n",
    "        else:\n",
    "            for ev in tr:\n",
    "                traces[glue].append(ev)\n",
    "    return log_instance.EventLog(traces.values(), attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                     omni_present=log.omni_present, extensions=log.extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_log=Noise_double_head(log,10)\n",
    "noise_stream = sorting.sort_timestamp_stream(to_event_stream.transform_event_log_to_event_stream(noise_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_double_tail(log, percent):\n",
    "# random.choice(log)\n",
    "    noise_item=random.choices(population=log, k=int(len(log)*percent/100))\n",
    "    noise_case=[]\n",
    "    for k in noise_item:\n",
    "        noise_case.append(k.attributes['concept:name'])\n",
    "#     print(noise_case)\n",
    "    traces={}\n",
    "    for tr in log:\n",
    "        trace_attr={}\n",
    "        glue=tr.attributes['concept:name']\n",
    "        trace_attr[xes.DEFAULT_TRACEID_KEY] = glue\n",
    "        traces[glue] = log_instance.Trace(attributes=trace_attr)        \n",
    "        if tr.attributes['concept:name'] in noise_case:\n",
    "            trl=len(tr)\n",
    "            for nu,ev in enumerate(tr):\n",
    "                traces[glue].append(ev)\n",
    "                if nu == (trl-1):\n",
    "                    traces[glue].append(ev)\n",
    "        else:\n",
    "            for ev in tr:\n",
    "                traces[glue].append(ev)\n",
    "    return log_instance.EventLog(traces.values(), attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                     omni_present=log.omni_present, extensions=log.extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_log=Noise_double_tail(log,10)\n",
    "noise_stream = sorting.sort_timestamp_stream(to_event_stream.transform_event_log_to_event_stream(noise_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_trace_length(log):\n",
    "    tr_len = {}\n",
    "    for case_index, case in enumerate(log):\n",
    "        tr_len[case.attributes[xes.DEFAULT_TRACEID_KEY]]=log[case_index].__len__()\n",
    "    return tr_len\n",
    "tr_len=all_trace_length(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##==============================NoDCL================================================\n",
    "streamd=deepcopy(stream)\n",
    "# streamd=deepcopy(noise_stream)\n",
    "mystream=sorting.sort_timestamp_stream(streamd)\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "\n",
    "# end event number\n",
    "num_events=mystream.__len__()\n",
    "# num_events=6000\n",
    "\n",
    "# start event number\n",
    "start_event=0\n",
    "# window size\n",
    "maxWinSize=1300\n",
    "\n",
    "# pick a time scale for the statistic unit\n",
    "time_scale=60\n",
    "# time_scale=3600        #hours\n",
    "# time_scale=3600*24     #days\n",
    "\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "CaseIndNT={}\n",
    "# \n",
    "# index and event :time list\n",
    "CaseIndTime={}\n",
    "CaseEvtTime={}\n",
    "\n",
    "\n",
    "# confusion matrix of predict complete and actual complete\n",
    "df_ConfM = pd.DataFrame()\n",
    "\n",
    "#  event stream SLinding window\n",
    "esSL=[]\n",
    "\n",
    "# for record the current index\n",
    "i=start_event\n",
    "\n",
    "# Statistic for first and last case-activity dict\n",
    "first_act={}\n",
    "\n",
    "# Drop Case List\n",
    "DCL={}\n",
    "\n",
    "# All activity counter\n",
    "Allact1={}\n",
    "Allact2={}\n",
    "Lastact={}\n",
    "Followact={}\n",
    "\n",
    "df_Last = pd.DataFrame()\n",
    "df_Follow = pd.DataFrame()\n",
    "\n",
    "for event in itertools.islice(mystream , start_event, num_events):\n",
    "\n",
    "    glue = event[case_glue]\n",
    "    current_time=event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "    if event[xes.DEFAULT_NAME_KEY] not in Allact2:\n",
    "        Allact1['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Allact2['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Lastact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Followact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "    Allact2['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "# start statistic of distribution\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "# Dict:CaseIndTime record the {index activity:[after index activity time]}\n",
    "# Dict:CaseEvtTime record the {activity name:[after activity time]}\n",
    "    if glue not in CaseIndNT.keys():\n",
    "        CaseIndNT[glue] = {}\n",
    "        CaseIndNT[glue]['EvtIndex'] = [1]\n",
    "        CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "        CaseIndNT[glue]['1_activity'] = event[xes.DEFAULT_NAME_KEY]\n",
    "        if glue not in DCL:\n",
    "            first_act[glue] = event[xes.DEFAULT_NAME_KEY]\n",
    "    else:\n",
    "        CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "        CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale        \n",
    "        # mark if the event repeat or not\n",
    "#         repeat_val=1\n",
    "#         if event[xes.DEFAULT_NAME_KEY] in CaseIndNT[glue].values():\n",
    "#             repeat_val+=1\n",
    "#             event[xes.DEFAULT_NAME_KEY]=event[xes.DEFAULT_NAME_KEY]+('_%d'%repeat_val)\n",
    "        CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "        \n",
    "        if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "        CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "        \n",
    "        if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "            CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "        CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "        CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "        # Count the follow activity \n",
    "        Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1   \n",
    "\n",
    "\n",
    "\n",
    "# Do sliding window on list:esSL(event stream SLiding )\n",
    "# Dropping from the front of sliding window\n",
    "    if len(esSL) < maxWinSize:\n",
    "        esSL.append(event)\n",
    "    else:\n",
    "        if len(CaseIndNT[esSL[0][case_glue]]['EvtIndex'])==1:\n",
    "            DCL[esSL[0][case_glue]]={}\n",
    "            DCL[esSL[0][case_glue]]['index']=CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1]\n",
    "            DCL[esSL[0][case_glue]]['act']=CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1])]\n",
    "            DCL[esSL[0][case_glue]]['time']=CaseIndNT[esSL[0][case_glue]]['event_time_newest']\n",
    "            del CaseIndNT[esSL[0][case_glue]]\n",
    "# Count the last activity \n",
    "            Lastact['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1     \n",
    "        else:\n",
    "            del CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['time_after_%d'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0]\n",
    "# Count all the activity \n",
    "        Allact1['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1\n",
    "\n",
    "        del esSL[0]            \n",
    "        esSL.append(event)\n",
    "        \n",
    "\n",
    "    Lastactdic={}\n",
    "    for k in Lastact:\n",
    "        if Allact1[k]>0:\n",
    "            Lastactdic[k]=Lastact[k]/Allact1[k]\n",
    "    df_Last=df_Last.append(Lastactdic , ignore_index=True)    \n",
    "\n",
    "    Followactdic={}\n",
    "    for k in Followact:\n",
    "        if Allact2[k]>0:\n",
    "            Followactdic[k]=1-Followact[k]/Allact2[k]\n",
    "    df_Follow=df_Follow.append(Followactdic , ignore_index=True)   \n",
    "    \n",
    "    # for checking the code running state\n",
    "    if (i%500==0):\n",
    "        print(i,'/',(num_events))\n",
    "    i=i+1\n",
    "\n",
    "df_Last=df_Last.transpose()\n",
    "df_Follow=df_Follow.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##======================================w/ DCL================================================\n",
    "streamd=deepcopy(stream)\n",
    "# streamd=deepcopy(noise_stream)\n",
    "mystream=sorting.sort_timestamp_stream(streamd)\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "\n",
    "# end event number\n",
    "num_events=mystream.__len__()\n",
    "# num_events=6000\n",
    "\n",
    "# start event number\n",
    "start_event=0\n",
    "# window size\n",
    "maxWinSize=4000\n",
    "\n",
    "# pick a time scale for the statistic unit\n",
    "# time_scale=60\n",
    "time_scale=3600        #hours\n",
    "# time_scale=3600*24     #days\n",
    "\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "CaseIndNT={}\n",
    "# \n",
    "# index and event :time list\n",
    "CaseIndTime={}\n",
    "CaseEvtTime={}\n",
    "\n",
    "\n",
    "# confusion matrix of predict complete and actual complete\n",
    "df_ConfM = pd.DataFrame()\n",
    "\n",
    "#  event stream SLinding window\n",
    "esSL=[]\n",
    "\n",
    "# for record the current index\n",
    "i=start_event\n",
    "\n",
    "# Statistic for first and last case-activity dict\n",
    "first_act={}\n",
    "\n",
    "# Drop Case List\n",
    "DCL={}\n",
    "\n",
    "# All activity counter\n",
    "Allact1={}\n",
    "Allact2={}\n",
    "Lastact={}\n",
    "Followact={}\n",
    "\n",
    "df_Last = pd.DataFrame()\n",
    "df_Follow = pd.DataFrame()\n",
    "\n",
    "for event in itertools.islice(mystream , start_event, num_events):\n",
    "\n",
    "    glue = event[case_glue]\n",
    "    current_time=event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "    if event[xes.DEFAULT_NAME_KEY] not in Allact2:\n",
    "        Allact1['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Allact2['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Lastact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "        Followact['%s'%(event[xes.DEFAULT_NAME_KEY])]=0\n",
    "    Allact2['%s'%(event[xes.DEFAULT_NAME_KEY])]+=1\n",
    "# start statistic of distribution\n",
    "# Dict:CaseIndNT record the {case-id:{index activity name: name, index activity time: time}}\n",
    "# Dict:CaseIndTime record the {index activity:[after index activity time]}\n",
    "# Dict:CaseEvtTime record the {activity name:[after activity time]}\n",
    "    if glue in DCL:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            Lastact['%s'%(DCL[glue]['act'])]-=1\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex']=[DCL[glue]['index']+1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])]=event[xes.DEFAULT_NAME_KEY]\n",
    "            if (DCL[glue]['act']) not in CaseEvtTime:\n",
    "                CaseEvtTime[DCL[glue]['act']] = []\n",
    "            CaseEvtTime[DCL[glue]['act']].append((event[xes.DEFAULT_TIMESTAMP_KEY] - DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(DCL[glue]['index'])) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((DCL[glue]['index']))] = []\n",
    "            CaseIndTime['time_after_%d'%(DCL[glue]['index'])].append((event[xes.DEFAULT_TIMESTAMP_KEY] -DCL[glue]['time']).total_seconds()/ time_scale)\n",
    "            Followact['%s'%(DCL[glue]['act'])]+=1\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY] \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1  \n",
    "    else:\n",
    "        if glue not in CaseIndNT.keys():\n",
    "            CaseIndNT[glue] = {}\n",
    "            CaseIndNT[glue]['EvtIndex'] = [1]\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]\n",
    "            CaseIndNT[glue]['1_activity'] = event[xes.DEFAULT_NAME_KEY]\n",
    "            first_act[glue] = event[xes.DEFAULT_NAME_KEY]\n",
    "        else:\n",
    "            CaseIndNT[glue]['EvtIndex'].append(CaseIndNT[glue]['EvtIndex'][-1]+1)\n",
    "            CaseIndNT[glue]['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] = (event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale\n",
    "            CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1])] = event[xes.DEFAULT_NAME_KEY]\n",
    "            if CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)] not in CaseEvtTime:\n",
    "                CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]] = []\n",
    "            CaseEvtTime[CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)]].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "\n",
    "            if ('time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)) not in CaseIndTime:\n",
    "                CaseIndTime['time_after_%d'%((CaseIndNT[glue]['EvtIndex'][-1]-1))] = []\n",
    "            CaseIndTime['time_after_%d'%(CaseIndNT[glue]['EvtIndex'][-1]-1)].append((event[xes.DEFAULT_TIMESTAMP_KEY] - CaseIndNT[glue]['event_time_newest']).total_seconds()/ time_scale)\n",
    "            CaseIndNT[glue]['event_time_newest'] = event[xes.DEFAULT_TIMESTAMP_KEY]  \n",
    "            # Count the follow activity \n",
    "            Followact['%s'%(CaseIndNT[glue]['%d_activity'%(CaseIndNT[glue]['EvtIndex'][-1]-1)])]+=1   \n",
    "\n",
    "# Do sliding window on list:esSL(event stream SLiding )\n",
    "# Dropping from the front of sliding window\n",
    "    if len(esSL) < maxWinSize:\n",
    "        esSL.append(event)\n",
    "    else:\n",
    "        if len(CaseIndNT[esSL[0][case_glue]]['EvtIndex'])==1:\n",
    "            # Count the last activity \n",
    "            Lastact['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1   \n",
    "            DCL[esSL[0][case_glue]]={}\n",
    "            DCL[esSL[0][case_glue]]['index']=CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1]\n",
    "            DCL[esSL[0][case_glue]]['act']=CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][-1])]\n",
    "            DCL[esSL[0][case_glue]]['time']=CaseIndNT[esSL[0][case_glue]]['event_time_newest']\n",
    "            del CaseIndNT[esSL[0][case_glue]]\n",
    "  \n",
    "        else:\n",
    "            del CaseIndNT[esSL[0][case_glue]]['%d_activity'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['time_after_%d'%(CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0])]\n",
    "            del CaseIndNT[esSL[0][case_glue]]['EvtIndex'][0]\n",
    "# Count all the activity \n",
    "        Allact1['%s'%(esSL[0][xes.DEFAULT_NAME_KEY])]+=1\n",
    "\n",
    "        del esSL[0]            \n",
    "        esSL.append(event)\n",
    "        \n",
    "\n",
    "    Lastactdic={}\n",
    "    for k in Lastact:\n",
    "        if Allact1[k]>0:\n",
    "            Lastactdic[k]=Lastact[k]/Allact1[k]\n",
    "    df_Last=df_Last.append(Lastactdic , ignore_index=True)    \n",
    "\n",
    "    Followactdic={}\n",
    "    for k in Followact:\n",
    "        if Allact2[k]>0:\n",
    "            Followactdic[k]=1-Followact[k]/Allact2[k]\n",
    "    df_Follow=df_Follow.append(Followactdic , ignore_index=True)   \n",
    "    \n",
    "    # for checking the code running state\n",
    "    if (i%500==0):\n",
    "        print(i,'/',(num_events))\n",
    "    i=i+1\n",
    "\n",
    "df_Last=df_Last.transpose()\n",
    "df_Follow=df_Follow.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "fig_row=2\n",
    "fig_col = math.ceil(len(Followactdic)/fig_row)\n",
    "\n",
    "f, axes = plt.subplots(fig_row,fig_col,figsize=(20,12))\n",
    "i=1\n",
    "for k in Followactdic:\n",
    "#     print(k)\n",
    "    plt.subplot(fig_row, fig_col, i)\n",
    "\n",
    "    plt.plot(df_Last.loc[ '%s'%k , :],'C0',label=('Last'))\n",
    "    plt.plot(df_Follow.loc[ '%s'%k , :],'C1',label=('Follow'))\n",
    "    if (k != 'Act_H'):\n",
    "        plt.axhline(y=0.05, color='r', linestyle='-',label=('0.05'))\n",
    "#     if (k == 'Act_E'):\n",
    "#         plt.axvline(x=15000, color='g', linestyle='-',label=('15000'))\n",
    "    plt.title('%s'%k)\n",
    "    plt.ylim(0,1.05)\n",
    "    plt.legend()\n",
    "    i+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of active trace on timestep\n",
    "\n",
    "# call (length of trace-1)=count when first time see the trace\n",
    "# (count-1) when see the trace each time\n",
    "# add up all trace that count >=0\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "count_dic={}\n",
    "num_act_list=[]\n",
    "for event in mystream:\n",
    "    if event[case_glue] in count_dic:\n",
    "        count_dic[event[case_glue]]=count_dic[event[case_glue]]-1\n",
    "    else:\n",
    "        count_dic[event[case_glue]]=tr_len[event[case_glue]]-1\n",
    "    num_act=0\n",
    "    for k,v in count_dic.items():\n",
    "        if v !=0:\n",
    "            num_act=num_act+1\n",
    "    num_act_list.append(num_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(num_act_list,label='# active case')\n",
    "plt.plot(index,count_full,label='# complete trace')\n",
    "# plt.axhline(y=190.5, color='k', linestyle='-',label=('avg(1k-13.3k)'))\n",
    "plt.axhline(y=1, color='k', linestyle='-',label=('avg(1k-13.3k)'))\n",
    "plt.ylabel('# active case')\n",
    "plt.xlabel('# index')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(num_act_list[1000:13300])/len(num_act_list[1000:13300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pm4py.algo.simulation.playout import factory as playout\n",
    "from pm4py.algo.simulation.playout.versions import basic_playout\n",
    "gen_log=basic_playout.apply_playout(my_net[0],my_net[1],no_traces=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gen_log[1])\n",
    "for i in gen_log[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for case_index, case in enumerate(gen_log):\n",
    "    print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "    for event_index, event in enumerate(case):\n",
    "        print(\"event index: %d  event activity: %s  timestamp: %s\" % (event_index, event[\"concept:name\"],event[\"time:timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.evaluation.replay_fitness.versions import alignment_based\n",
    "from pm4py.evaluation.precision.versions import etconformance_token\n",
    "fitness_wholeNet = alignment_based.apply(log, net, initial_marking, final_marking)\n",
    "precision_wholeNet = etconformance_token.apply(log, net, initial_marking, final_marking)\n",
    "print(fitness_wholeNet)\n",
    "print('precision:',precision_wholeNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es2.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(precisionLog,'C0')\n",
    "# plt.plot(precisionLogSL,'C1')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py import util as pmutil\n",
    "from pm4py.objects.conversion.log import constants\n",
    "from pm4py.objects.log import log as log_instance\n",
    "from pm4py.objects.log.util import general as log_util\n",
    "from pm4py.objects.log.util import xes\n",
    "def transform_event_to_list(event, traces,\n",
    "                            case_glue=log_util.CASE_ATTRIBUTE_GLUE, \n",
    "                            include_case_attributes=True,\n",
    "                            case_attribute_prefix=log_util.CASE_ATTRIBUTE_PREFIX):\n",
    "    glue = event[case_glue]\n",
    "    if glue not in traces:\n",
    "        trace_attr = {}\n",
    "        if include_case_attributes:\n",
    "            for k in event.keys():\n",
    "                if k.startswith(case_attribute_prefix):\n",
    "                    trace_attr[k.replace(case_attribute_prefix, '')] = event[k]\n",
    "            if xes.DEFAULT_TRACEID_KEY not in trace_attr:\n",
    "                trace_attr[xes.DEFAULT_TRACEID_KEY] = glue\n",
    "        traces[glue] = log_instance.Trace(attributes=trace_attr)\n",
    "\n",
    "    if include_case_attributes:\n",
    "        for k in list(event.keys()):\n",
    "            if k.startswith(case_attribute_prefix):\n",
    "                del event[k]\n",
    "    traces[glue].append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#------------------------only keep full trace inside window----------------\n",
    "streamd=deepcopy(stream)\n",
    "# mystream=sorting.sort_timestamp_stream(streamd)\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "\n",
    "# How many events for event stream\n",
    "EventsNum = mystream.__len__()\n",
    "# EventsNum = 4000\n",
    "\n",
    "\n",
    "i=0\n",
    "df_fitness_new = pd.DataFrame()\n",
    "df_precision_new = pd.DataFrame()\n",
    "\n",
    "for maxWinSize in [1000]:\n",
    "    esSL=[]\n",
    "    index=[]\n",
    "    count_full=[]\n",
    "    fitnessLog=[]\n",
    "    fitnessLogF=[]\n",
    "    precisionLog=[]\n",
    "    precisionLogF=[]\n",
    "    i=0\n",
    "    df_result=[]\n",
    "    for event in itertools.islice(mystream , 0, EventsNum):\n",
    "        \n",
    "        if (i%1000==0):\n",
    "            print(i,'/',EventsNum)\n",
    "        i=i+1\n",
    "        if len(esSL) < maxWinSize:\n",
    "            esSL.append(event)\n",
    "        else:\n",
    "            del esSL[0]\n",
    "            esSL.append(event)\n",
    "            \n",
    "        if i %200==0:\n",
    "#         if i == 5500:\n",
    "            index.append(i)\n",
    "            ESSL_allwindow=deepcopy(esSL)\n",
    "            es3_allwindow=log_instance.EventStream(ESSL_allwindow, attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                            omni_present=log.omni_present, extensions=log.extensions)\n",
    "            elog3_allwindow = to_event_log.transform_event_stream_to_event_log(es3_allwindow)\n",
    "            SLW_net, SLW_initial_marking, SLW_final_marking = inductive_miner.apply(elog3_allwindow)\n",
    "\n",
    "            WinTrlen={}\n",
    "            for itessl in esSL:\n",
    "                if itessl[case_glue] in WinTrlen:\n",
    "                    WinTrlen[itessl[case_glue]]+=1\n",
    "                else:\n",
    "                    WinTrlen[itessl[case_glue]]=1\n",
    "            fullInWin=[]\n",
    "            for k,v in WinTrlen.items():\n",
    "                if v == tr_len[k]:\n",
    "                    fullInWin.append(k)\n",
    "            \n",
    "            esSLfull=[]\n",
    "            for itessl in esSL:\n",
    "                if itessl[case_glue] in fullInWin:\n",
    "                    esSLfull.append(itessl) \n",
    "            count_full.append(len(fullInWin))\n",
    "            ESSL=deepcopy(esSLfull)\n",
    "            es3=log_instance.EventStream(ESSL, attributes=log.attributes, classifiers=log.classifiers,\n",
    "                                            omni_present=log.omni_present, extensions=log.extensions)\n",
    "            elog3 = to_event_log.transform_event_stream_to_event_log(es3)\n",
    "            SLF_net, SLF_initial_marking, SLF_final_marking = inductive_miner.apply(elog3)\n",
    "\n",
    "            fitness_log = alignment_based.apply(log, SLW_net, SLW_initial_marking, SLW_final_marking)\n",
    "            fitness_logF = alignment_based.apply(log, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "            precision_log = etconformance_token.apply(log, SLW_net, SLW_initial_marking, SLW_final_marking)\n",
    "            precision_logF = etconformance_token.apply(log, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "            fitnessLog.append(fitness_log['averageFitness'])\n",
    "            fitnessLogF.append(fitness_logF['averageFitness'])\n",
    "            precisionLog.append(precision_log)\n",
    "            precisionLogF.append(precision_logF)\n",
    "\n",
    "#     df_result['%d_Fitraw'%(maxWinSize)] = fitnessLog\n",
    "#     df_result['%d_Fitnew'%(maxWinSize)] = fitnessLogF\n",
    "#     df_result['%d_Preraw'%(maxWinSize)] = precisionLog\n",
    "#     df_result['%d_Prenew'%(maxWinSize)] = precisionLogF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------# count full trace inside window----------------\n",
    "streamd=deepcopy(stream)\n",
    "# mystream=sorting.sort_timestamp_stream(streamd)\n",
    "case_glue=log_util.CASE_ATTRIBUTE_GLUE\n",
    "\n",
    "# How many events for event stream\n",
    "EventsNum = mystream.__len__()\n",
    "# EventsNum = 4000\n",
    "\n",
    "\n",
    "i=0\n",
    "df_fitness_new = pd.DataFrame()\n",
    "df_precision_new = pd.DataFrame()\n",
    "\n",
    "for maxWinSize in [4000]:\n",
    "    esSL=[]\n",
    "    index=[]\n",
    "    count_full=[]\n",
    "\n",
    "    i=0\n",
    "    df_result=[]\n",
    "    for event in itertools.islice(mystream , 0, EventsNum):\n",
    "        \n",
    "        if (i%1000==0):\n",
    "            print(i,'/',EventsNum)\n",
    "        i=i+1\n",
    "        if len(esSL) < maxWinSize:\n",
    "            esSL.append(event)\n",
    "        else:\n",
    "            del esSL[0]\n",
    "            esSL.append(event)\n",
    "        if True:\n",
    "#         if i %200==0:\n",
    "#         if i == 5500:\n",
    "            index.append(i)\n",
    "#             ESSL_allwindow=deepcopy(esSL)\n",
    "#             es3_allwindow=log_instance.EventStream(ESSL_allwindow, attributes=log.attributes, classifiers=log.classifiers,\n",
    "#                                             omni_present=log.omni_present, extensions=log.extensions)\n",
    "#             elog3_allwindow = to_event_log.transform_event_stream_to_event_log(es3_allwindow)\n",
    "#             SLW_net, SLW_initial_marking, SLW_final_marking = inductive_miner.apply(elog3_allwindow)\n",
    "\n",
    "            WinTrlen={}\n",
    "            for itessl in esSL:\n",
    "                if itessl[case_glue] in WinTrlen:\n",
    "                    WinTrlen[itessl[case_glue]]+=1\n",
    "                else:\n",
    "                    WinTrlen[itessl[case_glue]]=1\n",
    "            fullInWin=[]\n",
    "            for k,v in WinTrlen.items():\n",
    "                if v == tr_len[k]:\n",
    "                    fullInWin.append(k)\n",
    "            \n",
    "            esSLfull=[]\n",
    "            for itessl in esSL:\n",
    "                if itessl[case_glue] in fullInWin:\n",
    "                    esSLfull.append(itessl) \n",
    "            count_full.append(len(fullInWin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SW_precision EMA\n",
    "fig = plt.subplots()\n",
    "\n",
    "ax1 = plt.subplot(211)\n",
    "# ax1.axhline(y=0.9222285714286074, color='r', linestyle='--',label='Whole log ')\n",
    "# ax1.plot(df_result['900_FitSWorg'],'C0',label='whole SW ')\n",
    "# ax1.plot(df_result['900_FitSWnew'],'C1',label='only complete trace inside SW')\n",
    "ax1.plot(fitnessLog,'C0',label='Raw SW ')\n",
    "ax1.plot(fitnessLogF,'C1',label='Filtered SW')\n",
    "\n",
    "ax1.set_ylim([0,1.05])\n",
    "ax1.title.set_text('fitness of Sliding Window w.r.t. complete log')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(212)\n",
    "# ax2.plot(df_result['900_PreSWorg'],'C0',label='whole SW ')\n",
    "# ax2.plot(df_result['900_PreSWnew'],'C1',label='only complete trace inside SW')\n",
    "# ax2.axhline(y=0.9720135032124578, color='r', linestyle='--',label='Whole log ')\n",
    "ax2.plot(precisionLog,'C0',label='Raw SW ')\n",
    "ax2.plot(precisionLogF,'C1',label='Filtered SW')\n",
    "\n",
    "ax2.set_ylim([0,1.05])\n",
    "ax2.title.set_text('precision of Sliding Window w.r.t. complete log')\n",
    "ax2.legend(loc=4)\n",
    "# ax2.plot(rolling_mean,'r',label='original SW')\n",
    "plt.subplots_adjust(hspace = 0.4 )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for case_index, case in enumerate(elog3_allwindow):\n",
    "for case_index, case in enumerate(elog3):\n",
    "    print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "    for event_index, event in enumerate(case):\n",
    "        print(\"event index: %d  event activity: %s  timestamp: %s\" % (event_index, event[\"concept:name\"],event[\"time:timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SLF_gviz_pn = pn_vis_factory.apply(SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "pn_vis_factory.view(SLF_gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLW_gviz_pn = pn_vis_factory.apply(SLW_net, SLW_initial_marking, SLW_final_marking)\n",
    "pn_vis_factory.view(SLW_gviz_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pn_vis_factory.save(SLW_gviz_pn,'/home/tsai/Dropbox/Process_Mining/OutputData/W10/RoadTrraffic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_wholeNet1 = alignment_based.apply(mylog, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "precision_wholeNet1 = etconformance_token.apply(mylog, SLF_net, SLF_initial_marking, SLF_final_marking)\n",
    "print(fitness_wholeNet1)\n",
    "print('precision:',precision_wholeNet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_wholeNet1 = alignment_based.apply(elog3_allwindow, SLW_net, SLW_initial_marking, SLW_final_marking)\n",
    "precision_wholeNet1 = etconformance_token.apply(elog3_allwindow, SLW_net, SLW_initial_marking, SLW_final_marking)\n",
    "print(fitness_wholeNet1)\n",
    "print('precision:',precision_wholeNet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "def example(env):\n",
    "    event = simpy.events.Timeout(env, delay=1, value=42)\n",
    "    value = yield event\n",
    "    print('now=%d, value=%d' % (env.now, value))\n",
    "env = simpy.Environment()\n",
    "example_gen = example(env)\n",
    "p = simpy.events.Process(env, example_gen)\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "\n",
    "# \n",
    "def car(env):\n",
    "    while True:\n",
    "        print('Start parking at %d' % env.now)\n",
    "        parking_duration = np.random.randint(2, 5)\n",
    "        yield env.timeout(parking_duration) #  5s\n",
    "        print('Start driving at %d' % env.now)\n",
    "        trip_duration = 2\n",
    "        yield env.timeout(trip_duration)   #  2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "env = simpy.Environment()   # \n",
    "env.process(car(env))    # \n",
    "env.run(until=15)   # ,  15s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class School:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.class_ends = env.event()\n",
    "        self.pupil_procs = [env.process(self.pupil()) for i in range(3)]\n",
    "        self.bell_proc = env.process(self.bell())\n",
    "\n",
    "    def bell(self):\n",
    "        for i in range(2):\n",
    "            print('i=%d in bell start'%i)\n",
    "            yield self.env.timeout(45)\n",
    "            print('\\nTime at %d' % env.now)\n",
    "            self.class_ends.succeed()\n",
    "            print('after succeed')\n",
    "#             print('class_ends triggered1',self.class_ends.triggered)\n",
    "#             print('class_ends ok',self.class_ends.ok)\n",
    "#             print('peek bell:',env.peek())\n",
    "            self.class_ends = self.env.event()\n",
    "            print('set class_ends=env.event')\n",
    "#             print('class_ends triggered2',self.class_ends.triggered)\n",
    "#             self.class_ends = env.event()\n",
    "            print('i=%d in bell end'%i)\n",
    "\n",
    "    def pupil(self):\n",
    "        for i in range(2):\n",
    "            print('i=%d in pupil start'%i)\n",
    "#             print('class_ends triggered0',self.class_ends.triggered)\n",
    "            print(r' \\o/', end='')\n",
    "            print('\\tTime at %d' % env.now)\n",
    "            yield self.class_ends   \n",
    "            print('i=%d in pupil end'%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simpy.Environment()\n",
    "school = School(env)\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2):\n",
    "#     print(r' \\o/', end='')\n",
    "# dir(school.class_ends)\n",
    "school.pupil_procs[0]._desc\n",
    "# school.bell_proc.triggered\n",
    "# env.event()\n",
    "# school.class_ends.triggered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randint\n",
    "seed(23)\n",
    "\n",
    "import simpy\n",
    "\n",
    "class EV:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.drive_proc = env.process(self.drive(env))\n",
    "        self.bat_ctrl_proc = env.process(self.bat_ctrl(env))\n",
    "        self.bat_ctrl_reactivate = env.event()\n",
    "        self.bat_ctrl_sleep = env.event()\n",
    "\n",
    "\n",
    "    def drive(self, env):\n",
    "        \"\"\"\"\"\"\n",
    "        while True:\n",
    "            #  20-40 \n",
    "            print(\" : \", env.now)\n",
    "            yield env.timeout(randint(20, 40))\n",
    "            print(\" : \", env.now)\n",
    "\n",
    "            #  1-6 \n",
    "            print(\" : \", env.now)\n",
    "            self.bat_ctrl_reactivate.succeed()  # \n",
    "            self.bat_ctrl_reactivate = env.event()\n",
    "            yield env.timeout(randint(60, 360)) & self.bat_ctrl_sleep # \n",
    "            print(\" :\", env.now)\n",
    "\n",
    "    def bat_ctrl(self, env):\n",
    "        \"\"\"\"\"\"\n",
    "        while True:\n",
    "            print(\" :\", env.now)\n",
    "            yield self.bat_ctrl_reactivate  # \n",
    "            print(\" :\", env.now)\n",
    "            yield env.timeout(randint(30, 90))\n",
    "            print(\" :\", env.now)\n",
    "            self.bat_ctrl_sleep.succeed()\n",
    "            self.bat_ctrl_sleep = env.event()\n",
    "\n",
    "def main():\n",
    "    env = simpy.Environment()\n",
    "    ev = EV(env)\n",
    "    env.run(until=300)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfunc(env):\n",
    "    print(env.active_process)\n",
    "def my_proc(env):\n",
    "    while True:\n",
    "        print(env.active_process)  # will print \"p1\"\n",
    "        subfunc(env)\n",
    "        yield env.timeout(1)\n",
    "env = simpy.Environment()\n",
    "p1 = env.process(my_proc(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car(env, name, bcs, driving_time, charge_duration):\n",
    "...     # Simulate driving to the BCS\n",
    "...     yield env.timeout(driving_time)\n",
    "...\n",
    "...     # Request one of its charging spots\n",
    "# ...     print('%s arriving at %d' % (name, env.now))\n",
    "...     with bcs.request() as req:\n",
    "...         yield req\n",
    "...\n",
    "...         # Charge the battery\n",
    "...         print('%s resource %s' % (name, bcs.count))\n",
    "...         yield env.timeout(charge_duration)\n",
    "...         print('%s leaving the bcs at %s' % (name, env.now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "env = simpy.Environment()\n",
    "bcs = simpy.Resource(env, capacity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    env.process(car(env, 'Car %d' % i, bcs, i*2, randint(5, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time stamp interval = 1 sec\n",
    "import pm4py.objects.log.log as log_instance\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "from datetime import timedelta\n",
    "curr_timestamp=datetime.datetime(2010, 1, 1, 0, 0, 0, 0, pytz.UTC)\n",
    "stream = log_instance.EventStream()\n",
    "# How many cases to generate\n",
    "no_traces=4\n",
    "for i in range(no_traces):\n",
    "#     random.seed(i)\n",
    "    #choose a TargetLog(TL) from Log repository\n",
    "    SL=random.choice(L)\n",
    "    for k in SL:\n",
    "        event = log_instance.Event()\n",
    "        event[\"case:concept:name\"] = 'case_'+str(i)\n",
    "        event[\"concept:name\"] = k\n",
    "        event[\"time:timestamp\"] = curr_timestamp\n",
    "        trace.append(event)\n",
    "        dtime=np.random.randint(0, 5)\n",
    "        yield env.timeout(dtime)\n",
    "        curr_timestamp = curr_timestamp + timedelta(hours=dtime)\n",
    "        stream.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gen_ev(env, bcs, Log, concept_name,curr_timestamp):\n",
    "    with bcs.request() as req:\n",
    "        yield req\n",
    "        \n",
    "        SL=random.choice(L)\n",
    "        for k in SL:\n",
    "            dtime=np.random.randint(0, 5)\n",
    "            event = log_instance.Event()\n",
    "            event[\"case:concept:name\"] = 'case_'+str(concept_name)\n",
    "            event[\"concept:name\"] = k\n",
    "            event[\"time:timestamp\"] = curr_timestamp + timedelta(hours=env.now)\n",
    "#             event[\"worker_ID\"] = workers_ID\n",
    "            trace.append(event)\n",
    "            stream.append(event)\n",
    "            yield env.timeout(dtime)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time stamp interval = 1 sec\n",
    "import pm4py.objects.log.log as log_instance\n",
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "from datetime import timedelta\n",
    "curr_timestamp=datetime.datetime(2010, 1, 1, 0, 0, 0, 0, pytz.UTC)\n",
    "stream = log_instance.EventStream()\n",
    "# How many cases to generate\n",
    "no_traces=4\n",
    "workers=1\n",
    "\n",
    "env = simpy.Environment()\n",
    "bcs = simpy.Resource(env, capacity=workers)\n",
    "for i in range(no_traces):\n",
    "    env.process(Gen_ev(env, bcs, L, i ,curr_timestamp ))\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_index,event in enumerate(stream):\n",
    "    print(\"case:concept:name: %s  event activity: %s  timestamp: %s \" % (event['case:concept:name'], event[\"concept:name\"],event[\"time:timestamp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
